[
["index.html", "SEM and R Chapter 1 SEM and R", " SEM and R Bill 2021-04-22 Chapter 1 SEM and R This is the starting point. "],
["intro.html", "Chapter 2 Introduction 2.1 Definitions (Basic Concepts) 2.2 The path diagram 2.3 Lavaan syntax 2.4 Regression and path analysis", " Chapter 2 Introduction The following R codes and texts are from UCLA website “https://stats.idre.ucla.edu/r/seminars/rsem/” and I do not own the copyright of the R codes or texts. I wrote this R Markdown file for my own study purpose. Given this consideration, please do NOT distribute this page in any way. 2.1 Definitions (Basic Concepts) 2.1.1 Observed variable Observed variable: A variable that exists in the data (a.k.a item or manifest variable) 2.1.2 Latent variable Latent variable: A variable that is constructed and does not exist in the data. 2.1.3 Exogenous variable Exogenous variable: An independent variable either observed (X) or latent (\\(\\xi\\)) that explains an engogenous variable. 2.1.4 Endogenous variable Endogenous variable: A dependent variable, either observed (Y) or latent (\\(\\eta\\)) that has a causal path leading to it. 2.1.5 Measurement model Measurement model: A model that links obseved variables with latent variables. 2.1.6 Indicator (in a measurement model) Indicator: An observed variable in a measurement model (can be exogenous or endogenous). 2.1.7 Factor Factor: A latent variable defined by its indicators (can be exogenous or endogeous). 2.1.8 Loading Loading: A path between an indicator and a factor. 2.1.9 Structural model Structural model: A model that specifies casual relationships among exogeous variables to endogeous variables (can be observed or latent). 2.1.10 Regerssion path Regression path: A path between exogeous and endogeous variables (can be observed or latent). 2.2 The path diagram Circles represent latent variables. Squares represent observed indicators. Triangles represent intercepts or means. One way arrows represent paths. Two-way arrows represent either variances or covariances. 2.3 Lavaan syntax \\(\\sim\\) predict: used for regression of observed outcome to observed predictors (e.g., \\(y \\sim x\\)). \\(= \\sim\\) indicator: used for latent variable to observed indicator in factor analysis measurement models (e.g., \\(f= \\sim q+r+s\\)). \\(\\sim \\sim\\) covariance: (e.g., \\(x \\sim \\sim x\\)). \\(\\sim 1\\) intercept or mean: (e.g., \\(x \\sim 1\\) estimates the mean of variable \\(x\\)). \\(1*\\) fixes parameter or loading to one: (e.g., \\(f =\\sim 1*q\\)). \\(NA *\\) free parameter or loading: used to override default marker method (e.g., \\(f=\\sim NA * q\\)). \\(a*\\) lables the parameter ‘a’: used for model constraints (e.g., \\(f=\\sim a*q\\)). 2.4 Regression and path analysis \\[y_{1}=b_{0}+b_{1}x_{1}+\\epsilon_{1}\\] \\[y_{1}=\\alpha+\\gamma_{1} x_{1}+\\zeta_{1}\\] \\(x_{1}\\) single exogenous variable \\(y_{1}\\) single endogenous variable \\(b_{0}\\), \\(\\alpha_{1}\\) intercept of \\(y_{1}\\) (alpha) \\(b_{1}\\), \\(\\gamma_{1}\\) regression coefficient (gamma) \\(\\epsilon_{1}\\), \\(\\zeta_{1}\\) residual of \\(y_{1}\\) (epsilon, zeta) \\(\\phi\\) variance or covariance of the exogenous variable (phi) \\(\\psi\\) residual variance or covariance of the endogenous variable (psi) "],
["real-data-example-simple-linear-regression.html", "Chapter 3 Real data example (Simple linear regression) 3.1 Read the data into the R Studio environment.", " Chapter 3 Real data example (Simple linear regression) 3.1 Read the data into the R Studio environment. It also calcuates the covariance matrix among all the variables in the data. dat &lt;- read.csv(&quot;https://stats.idre.ucla.edu/wp-content/uploads/2021/02/worland5.csv&quot;) cov(dat) ## motiv harm stabi ppsych ses verbal read arith spell ## motiv 100 77 59 -25 25 32 53 60 59 ## harm 77 100 58 -25 26 25 42 44 45 ## stabi 59 58 100 -16 18 27 36 38 38 ## ppsych -25 -25 -16 100 -42 -40 -39 -24 -31 ## ses 25 26 18 -42 100 40 43 37 33 ## verbal 32 25 27 -40 40 100 56 49 48 ## read 53 42 36 -39 43 56 100 73 87 ## arith 60 44 38 -24 37 49 73 100 72 ## spell 59 45 38 -31 33 48 87 72 100 var(dat$motiv) ## [1] 100 In the following, we conduct a simple linear regression. \\[sample \\ variance-covariance \\ matrix \\hat{\\sum} = \\mathbf{S} \\] m1a &lt;- lm(read ~ motiv, data=dat) (fit1a &lt;-summary(m1a)) ## ## Call: ## lm(formula = read ~ motiv, data = dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -26.0995 -6.1109 0.2342 5.2237 24.0183 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.232e-07 3.796e-01 0.00 1 ## motiv 5.300e-01 3.800e-02 13.95 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 8.488 on 498 degrees of freedom ## Multiple R-squared: 0.2809, Adjusted R-squared: 0.2795 ## F-statistic: 194.5 on 1 and 498 DF, p-value: &lt; 2.2e-16 library(lavaan) ## Warning: package &#39;lavaan&#39; was built under R version 3.6.3 ## This is lavaan 0.6-8 ## lavaan is FREE software! Please report any bugs. #simple regression using lavaan m1b &lt;- &#39; # regressions read ~ 1+ motiv # variance (optional) motiv ~~ motiv &#39; fit1b &lt;- sem(m1b, data=dat) summary(fit1b) ## lavaan 0.6-8 ended normally after 14 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 5 ## ## Number of observations 500 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## read ~ ## motiv 0.530 0.038 13.975 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .read -0.000 0.379 -0.000 1.000 ## motiv 0.000 0.447 0.000 1.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## motiv 99.800 6.312 15.811 0.000 ## .read 71.766 4.539 15.811 0.000 "],
["real-data-example-multiple-linear-regression.html", "Chapter 4 Real data example (Multiple linear regression)", " Chapter 4 Real data example (Multiple linear regression) m2 &lt;- &#39; # regressions read ~ 1 + ppsych + motiv # covariance ppsych ~~ motiv &#39; fit2 &lt;- sem(m2, data=dat) summary(fit2) ## lavaan 0.6-8 ended normally after 34 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 500 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## read ~ ## ppsych -0.275 0.037 -7.385 0.000 ## motiv 0.461 0.037 12.404 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## ppsych ~~ ## motiv -24.950 4.601 -5.423 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .read 0.000 0.360 0.000 1.000 ## ppsych -0.000 0.447 -0.000 1.000 ## motiv 0.000 0.447 0.000 1.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .read 64.708 4.092 15.811 0.000 ## ppsych 99.800 6.312 15.811 0.000 ## motiv 99.800 6.312 15.811 0.000 "],
["bootstrapping.html", "Chapter 5 Bootstrapping 5.1 Introduction 5.2 Normal distribution, SD, SE 5.3 Sample function 5.4 Proportion 5.5 boot package 5.6 Concept of Percentile", " Chapter 5 Bootstrapping 5.1 Introduction The following note is made when I was studying Bret Larget’s note posted online. http://pages.stat.wisc.edu/~larget/stat302/chap3.pdf He used the data from LOck5data as an example. library(Lock5Data) data(CommuteAtlanta) str(CommuteAtlanta) ## &#39;data.frame&#39;: 500 obs. of 5 variables: ## $ City : Factor w/ 1 level &quot;Atlanta&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ Age : int 19 55 48 45 48 43 48 41 47 39 ... ## $ Distance: int 10 45 12 4 15 33 15 4 25 1 ... ## $ Time : int 15 60 45 10 30 60 45 10 25 15 ... ## $ Sex : Factor w/ 2 levels &quot;F&quot;,&quot;M&quot;: 2 2 2 1 1 2 2 1 2 1 ... time.mean = with(CommuteAtlanta, mean(Time)) time.mean ## [1] 29.11 Now, he sampled a (b X n) table. Note that, the Atlanta data has 500 row, as it has 500 observations (or, people). But, in the following new matrix, it is a (1000 times 500) table. Also, it should be noted that the logic of sample function in R. This webpage provides some insight into this function. Basically, the following R code randomly sample a bigger sample of (1000 times 500) from those 500 data points. After that, the matrix function put such (1000 times 500) data points into a matrix of (1000 times 500). B = 1000 n = nrow(CommuteAtlanta) boot.samples = matrix(sample(CommuteAtlanta$Time, size = B * n, replace = TRUE), B, n) Next, we need to calculate the mean for each row. Remember, we have 1000 rows. Note that, 1 in the apply function indicates that we calculate means on each row, whereas 2 indicates to each column. boot.statistics = apply(boot.samples, 1, mean) We can then plot all the means. require(ggplot2) ## Loading required package: ggplot2 ## Warning: package &#39;ggplot2&#39; was built under R version 3.6.3 ggplot(data.frame(meanTime = boot.statistics),aes(x=meanTime)) + geom_histogram(binwidth=0.25,aes(y=..density..)) + geom_density(color=&quot;red&quot;) time.se = sd(boot.statistics) time.se ## [1] 0.9177571 me = ceiling(10 * 2 * time.se)/10 me ## [1] 1.9 round(time.mean, 1) + c(-1, 1) * me ## [1] 27.2 31.0 5.2 Normal distribution, SD, SE Note, if we do not use bootstraping, we can use the standard CI formula (https://www.mathsisfun.com/data/confidence-interval.html). This formula assumes normal distribution. As we can see, this is close to the result based on the bootstrapping method. \\[\\overline{X} \\pm Z \\frac{S}{\\sqrt{n}}=29.11 \\pm 1.96 \\frac{20.72}{\\sqrt{500}}=27.29, 30.93\\] Note that, in the following, the author used 2 times SE to calculate the CI. The relationship between SD and SE: “Now the sample mean will vary from sample to sample; the way this variation occurs is described by the “sampling distribution” of the mean. We can estimate how much sample means will vary from the standard deviation of this sampling distribution, which we call the standard error (SE) of the estimate of the mean. As the standard error is a type of standard deviation, confusion is understandable. Another way of considering the standard error is as a measure of the precision of the sample mean.\" (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1255808/) boot.mean = function(x,B,binwidth=NULL) { n = length(x) boot.samples = matrix( sample(x,size=n*B,replace=TRUE), B, n) boot.statistics = apply(boot.samples,1,mean) se = sd(boot.statistics) require(ggplot2) if ( is.null(binwidth) ) binwidth = diff(range(boot.statistics))/30 p = ggplot(data.frame(x=boot.statistics),aes(x=x)) + geom_histogram(aes(y=..density..),binwidth=binwidth) + geom_density(color=&quot;red&quot;) plot(p) interval = mean(x) + c(-1,1)*2*se print( interval ) return( list(boot.statistics = boot.statistics, interval=interval, se=se, plot=p) ) } out = with(CommuteAtlanta, boot.mean(Distance, B = 1000)) ## [1] 16.90747 19.40453 5.3 Sample function To understand the function of sample in R. sample(20,replace = TRUE) ## [1] 14 20 15 17 17 3 3 5 11 6 13 8 15 11 14 18 4 9 5 13 The following uses loop to do the resampling. It uses sample function to index the numbers that they want to sample from the original sample. That is, [] suggests the indexing. n = length(CommuteAtlanta$Distance) B = 1000 result = rep(NA, B) for (i in 1:B) { boot.sample = sample(n, replace = TRUE) result[i] = mean(CommuteAtlanta$Distance[boot.sample]) } with(CommuteAtlanta, mean(Distance) + c(-1, 1) * 2 * sd(result)) ## [1] 16.90019 19.41181 5.4 Proportion So far, we have dealed with means. How about porpotions?Remember that, when calculating means, it starts with a single column of data to calculate the mean. Similarly, when calculating porpotions, you can just use a single column of data. reeses = c(rep(1, 11), rep(0, 19)) reeses.boot = boot.mean(reeses, 1000, binwidth = 1/30) ## [1] 0.1934925 0.5398408 However, if we have 48 students (i.e., 48 observations) and thus we have a bigger sample. However, how can we do re-sampling? Based on the note, it is kind of simple. They group them together and then resample from it. Note that, when they re-sampling, the programming do not distinguish the difference between 48 observations. But just combined them as a single column (741+699=1440), and then generate a very long column (1440 times 1000) and then reshape it into a matrix (1440 time 1000). This is the basic logic of the boot.mean function. reeses = c(rep(1, 741), rep(0, 699)) reeses.boot = boot.mean(reeses, 1000, binwidth = 0.005) ## [1] 0.4884387 0.5407279 5.5 boot package After having a basic idea of boostrapping, we can then use the package of boot. library(boot) ## Warning: package &#39;boot&#39; was built under R version 3.6.3 data(CommuteAtlanta) my.mean = function(x, indices) { return( mean( x[indices] ) ) } time.boot = boot(CommuteAtlanta$Time, my.mean, 10000) boot.ci(time.boot) ## Warning in boot.ci(time.boot): bootstrap variances needed for studentized ## intervals ## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS ## Based on 10000 bootstrap replicates ## ## CALL : ## boot.ci(boot.out = time.boot) ## ## Intervals : ## Level Normal Basic ## 95% (27.27, 30.95 ) (27.22, 30.90 ) ## ## Level Percentile BCa ## 95% (27.32, 31.00 ) (27.42, 31.17 ) ## Calculations and Intervals on Original Scale 5.6 Concept of Percentile require(Lock5Data) data(ImmuneTea) tea = with(ImmuneTea, InterferonGamma[Drink==&quot;Tea&quot;]) coffee = with(ImmuneTea, InterferonGamma[Drink==&quot;Coffee&quot;]) tea.mean = mean(tea) coffee.mean = mean(coffee) tea.n = length(tea) coffee.n = length(coffee) B = 500 # create empty arrays for the means of each sample tea.boot = numeric(B) coffee.boot = numeric(B) # Use a for loop to take the samples for ( i in 1:B ) { tea.boot[i] = mean(sample(tea,size=tea.n,replace=TRUE)) coffee.boot[i] = mean(sample(coffee,size=coffee.n,replace=TRUE)) } boot.stat = tea.boot - coffee.boot boot.stat ## [1] 29.5909091 11.6909091 10.1363636 13.0272727 33.3000000 15.2454545 ## [7] 4.3090909 13.2090909 12.7545455 17.1636364 30.6272727 16.5636364 ## [13] 18.7909091 15.9454545 18.8909091 22.8818182 13.0181818 19.3454545 ## [19] 6.0090909 22.2181818 30.2636364 0.4090909 13.3272727 13.8727273 ## [25] 19.6363636 23.3909091 18.3181818 11.5636364 17.4272727 21.2636364 ## [31] 20.0363636 23.2818182 6.8272727 23.4909091 19.3636364 22.7818182 ## [37] 17.3000000 8.3545455 29.4181818 7.0363636 26.6454545 2.6272727 ## [43] 11.3636364 21.4363636 23.0818182 10.3272727 17.1727273 15.2090909 ## [49] 15.6272727 30.3727273 21.3090909 4.9909091 28.5545455 10.5454545 ## [55] 16.8818182 6.1363636 18.6545455 18.9090909 3.4818182 21.7818182 ## [61] 28.8454545 24.5272727 22.1363636 16.6909091 2.1727273 14.8272727 ## [67] 28.2000000 18.4545455 10.8272727 5.2181818 26.6545455 19.5727273 ## [73] 2.0090909 24.5454545 33.9363636 23.7000000 19.7090909 26.5454545 ## [79] 16.6636364 27.5909091 28.5363636 26.3090909 16.2454545 -0.5272727 ## [85] 19.4272727 29.3727273 13.8454545 37.1272727 16.3090909 18.2000000 ## [91] 22.3090909 29.2181818 7.2090909 12.2909091 12.4272727 26.9363636 ## [97] 14.0000000 5.8727273 18.4545455 25.0454545 14.2000000 10.5000000 ## [103] 20.5818182 3.4000000 10.0272727 10.0000000 16.0181818 13.4181818 ## [109] 10.6818182 23.2272727 10.3636364 12.0545455 19.5000000 21.1727273 ## [115] 20.7181818 26.2272727 31.8363636 37.0454545 25.4909091 9.2272727 ## [121] 20.7000000 23.8636364 26.2454545 11.9090909 33.8818182 17.6909091 ## [127] 16.1000000 20.2909091 9.1272727 32.6909091 28.7090909 14.2545455 ## [133] 13.1363636 26.8727273 25.9090909 17.0818182 18.5000000 27.2181818 ## [139] 23.2181818 17.3272727 14.5090909 16.3727273 20.3272727 8.3909091 ## [145] 28.7727273 27.4000000 12.0818182 23.7000000 14.5636364 22.0545455 ## [151] 7.6363636 20.2000000 24.1545455 27.8272727 25.0181818 15.9636364 ## [157] 17.9181818 21.0545455 1.0636364 21.6000000 3.6909091 16.8545455 ## [163] 8.9363636 6.4454545 7.4909091 10.8272727 19.1272727 7.4272727 ## [169] 11.5181818 21.7363636 4.4181818 10.2090909 22.6454545 7.7636364 ## [175] 9.8272727 13.2090909 30.2090909 26.6363636 31.8363636 16.7909091 ## [181] 12.8363636 7.7181818 -3.4454545 9.3454545 20.1090909 28.7363636 ## [187] 17.1909091 17.5545455 21.1545455 14.3000000 23.2727273 13.7818182 ## [193] 6.2363636 14.6636364 17.9909091 15.2363636 19.1090909 19.7818182 ## [199] 27.6727273 9.1272727 9.7363636 14.0000000 25.9545455 20.9727273 ## [205] 13.4727273 10.7818182 13.3909091 8.8909091 14.4545455 14.3636364 ## [211] 15.9181818 17.1090909 13.4272727 7.8727273 -4.8636364 21.7181818 ## [217] 5.2272727 14.1545455 17.5363636 5.2000000 1.4272727 15.3545455 ## [223] 18.2090909 18.4181818 15.8000000 16.2727273 28.7000000 14.4363636 ## [229] 31.7363636 18.0272727 11.9909091 14.4272727 11.9636364 36.4727273 ## [235] 3.6272727 21.8909091 -3.5090909 27.5818182 23.7909091 2.1090909 ## [241] 28.8818182 21.4636364 15.1454545 18.1818182 12.8454545 8.4454545 ## [247] 9.8545455 25.0727273 8.7181818 15.2909091 20.1727273 2.9545455 ## [253] 2.1727273 18.4000000 18.2909091 -6.1636364 19.5909091 22.6636364 ## [259] 12.8636364 18.4818182 13.3363636 31.4181818 26.6454545 18.1363636 ## [265] 18.6000000 10.0363636 14.2272727 19.4181818 21.5545455 14.4454545 ## [271] 21.8909091 14.3727273 8.7272727 2.9272727 13.6545455 22.4818182 ## [277] 9.2363636 41.7727273 29.5181818 11.8454545 9.9545455 19.6727273 ## [283] 28.7000000 23.2636364 10.9272727 28.4727273 10.2181818 21.2727273 ## [289] 25.7909091 17.7909091 16.9272727 28.1727273 30.8454545 21.0909091 ## [295] 17.5818182 14.5909091 10.8545455 18.0181818 15.5272727 6.7272727 ## [301] 9.2545455 11.7818182 20.8545455 29.1363636 20.2636364 16.5818182 ## [307] 25.6272727 9.3818182 15.4454545 13.4454545 26.6454545 19.1727273 ## [313] 25.7000000 21.9727273 13.4000000 19.2272727 3.0090909 20.9363636 ## [319] 11.8818182 21.6272727 12.2363636 20.0090909 26.6454545 20.5454545 ## [325] 7.7181818 23.8363636 7.4363636 18.2545455 9.4545455 -0.2545455 ## [331] 9.7181818 20.6636364 18.6272727 4.7181818 18.8000000 14.1727273 ## [337] 10.9454545 5.7181818 15.8545455 22.3909091 16.2181818 13.1818182 ## [343] 10.8090909 -2.0272727 11.2727273 18.5909091 16.6363636 26.5545455 ## [349] 12.6818182 29.7272727 23.0181818 32.6818182 12.7545455 8.1909091 ## [355] 3.3636364 31.6545455 17.5000000 5.2636364 2.4000000 23.6909091 ## [361] 12.9272727 11.1454545 18.9909091 21.3636364 7.5272727 12.5272727 ## [367] 18.6909091 15.6909091 13.6272727 32.2090909 4.9181818 19.1090909 ## [373] 4.0090909 14.6363636 18.9181818 19.2454545 7.7636364 19.1363636 ## [379] 10.5545455 13.5727273 15.6000000 18.5636364 26.7090909 -0.2727273 ## [385] 19.3363636 1.9090909 28.3272727 14.9181818 29.5181818 13.7636364 ## [391] 6.6363636 24.0909091 8.1272727 16.8181818 33.0181818 18.6000000 ## [397] 7.2727273 6.6545455 15.3727273 29.8818182 31.5181818 18.0909091 ## [403] 17.7272727 24.3909091 9.6636364 18.2454545 19.2000000 12.7727273 ## [409] 19.5000000 28.2454545 14.7363636 10.4636364 -0.1000000 17.0000000 ## [415] 20.2272727 17.1454545 14.5181818 8.2909091 21.8454545 24.9363636 ## [421] 30.2545455 27.6000000 16.8545455 16.4272727 20.6090909 -2.1636364 ## [427] 13.1818182 21.0272727 14.4090909 6.6454545 22.4454545 33.9090909 ## [433] 15.1000000 12.9000000 25.0545455 18.7818182 21.8909091 16.0909091 ## [439] 27.9636364 13.2454545 20.6727273 3.2545455 23.2272727 7.7818182 ## [445] 22.9909091 10.0727273 22.2818182 11.9181818 12.8545455 16.7545455 ## [451] 18.3636364 3.1818182 11.4181818 18.7909091 22.2000000 20.0454545 ## [457] 15.6727273 6.9545455 16.4727273 31.3545455 24.1000000 17.8000000 ## [463] 21.4454545 12.0272727 15.4181818 23.4727273 27.0272727 16.8000000 ## [469] 15.9636364 32.3727273 16.4454545 9.4272727 15.3454545 9.0545455 ## [475] 15.8181818 23.9000000 10.5181818 21.1909091 23.1090909 24.7181818 ## [481] 21.5454545 8.8727273 24.4000000 26.9545455 10.6727273 12.8636364 ## [487] 31.2454545 10.1909091 19.0090909 25.2090909 5.1181818 23.3000000 ## [493] 6.8181818 19.3909091 20.9090909 16.6454545 10.0454545 18.9363636 ## [499] 20.8000000 19.5090909 # Find endpoints for 90%, 95%, and 99% bootstrap confidence intervals using percentiles. # 90%: 5% 95% quantile(boot.stat,c(0.05,0.95)) ## 5% 95% ## 3.358182 30.255000 # 95%: 2.5% 97.5% quantile(boot.stat,c(0.025,0.975)) ## 2.5% 97.5% ## 1.656136 32.032045 # 99%: 0.5% 99.5% quantile(boot.stat,c(0.005,0.995)) ## 0.5% 99.5% ## -3.477591 36.761955 "]
]
