[
["index.html", "SEM and R Chapter 1 SEM and R", " SEM and R Bill 2021-04-22 Chapter 1 SEM and R This is the starting point. "],
["intro.html", "Chapter 2 Introduction 2.1 Definitions (Basic Concepts) 2.2 The path diagram 2.3 Lavaan syntax 2.4 Regression and path analysis", " Chapter 2 Introduction The following R codes and texts are from UCLA website “https://stats.idre.ucla.edu/r/seminars/rsem/” and I do not own the copyright of the R codes or texts. I wrote this R Markdown file for my own study purpose. Given this consideration, please do NOT distribute this page in any way. 2.1 Definitions (Basic Concepts) 2.1.1 Observed variable Observed variable: A variable that exists in the data (a.k.a item or manifest variable) 2.1.2 Latent variable Latent variable: A variable that is constructed and does not exist in the data. 2.1.3 Exogenous variable Exogenous variable: An independent variable either observed (X) or latent (\\(\\xi\\)) that explains an engogenous variable. 2.1.4 Endogenous variable Endogenous variable: A dependent variable, either observed (Y) or latent (\\(\\eta\\)) that has a causal path leading to it. 2.1.5 Measurement model Measurement model: A model that links obseved variables with latent variables. 2.1.6 Indicator (in a measurement model) Indicator: An observed variable in a measurement model (can be exogenous or endogenous). 2.1.7 Factor Factor: A latent variable defined by its indicators (can be exogenous or endogeous). 2.1.8 Loading Loading: A path between an indicator and a factor. 2.1.9 Structural model Structural model: A model that specifies casual relationships among exogeous variables to endogeous variables (can be observed or latent). 2.1.10 Regerssion path Regression path: A path between exogeous and endogeous variables (can be observed or latent). 2.2 The path diagram Circles represent latent variables. Squares represent observed indicators. Triangles represent intercepts or means. One way arrows represent paths. Two-way arrows represent either variances or covariances. 2.3 Lavaan syntax \\(\\sim\\) predict: used for regression of observed outcome to observed predictors (e.g., \\(y \\sim x\\)). \\(= \\sim\\) indicator: used for latent variable to observed indicator in factor analysis measurement models (e.g., \\(f= \\sim q+r+s\\)). \\(\\sim \\sim\\) covariance: (e.g., \\(x \\sim \\sim x\\)). \\(\\sim 1\\) intercept or mean: (e.g., \\(x \\sim 1\\) estimates the mean of variable \\(x\\)). \\(1*\\) fixes parameter or loading to one: (e.g., \\(f =\\sim 1*q\\)). \\(NA *\\) free parameter or loading: used to override default marker method (e.g., \\(f=\\sim NA * q\\)). \\(a*\\) lables the parameter ‘a’: used for model constraints (e.g., \\(f=\\sim a*q\\)). 2.4 Regression and path analysis \\[y_{1}=b_{0}+b_{1}x_{1}+\\epsilon_{1}\\] \\[y_{1}=\\alpha+\\gamma_{1} x_{1}+\\zeta_{1}\\] \\(x_{1}\\) single exogenous variable \\(y_{1}\\) single endogenous variable \\(b_{0}\\), \\(\\alpha_{1}\\) intercept of \\(y_{1}\\) (alpha) \\(b_{1}\\), \\(\\gamma_{1}\\) regression coefficient (gamma) \\(\\epsilon_{1}\\), \\(\\zeta_{1}\\) residual of \\(y_{1}\\) (epsilon, zeta) \\(\\phi\\) variance or covariance of the exogenous variable (phi) \\(\\psi\\) residual variance or covariance of the endogenous variable (psi) "],
["real-data-example-simple-linear-regression.html", "Chapter 3 Real data example (Simple linear regression) 3.1 Read the data into the R Studio environment.", " Chapter 3 Real data example (Simple linear regression) 3.1 Read the data into the R Studio environment. It also calcuates the covariance matrix among all the variables in the data. dat &lt;- read.csv(&quot;https://stats.idre.ucla.edu/wp-content/uploads/2021/02/worland5.csv&quot;) cov(dat) ## motiv harm stabi ppsych ses verbal read arith spell ## motiv 100 77 59 -25 25 32 53 60 59 ## harm 77 100 58 -25 26 25 42 44 45 ## stabi 59 58 100 -16 18 27 36 38 38 ## ppsych -25 -25 -16 100 -42 -40 -39 -24 -31 ## ses 25 26 18 -42 100 40 43 37 33 ## verbal 32 25 27 -40 40 100 56 49 48 ## read 53 42 36 -39 43 56 100 73 87 ## arith 60 44 38 -24 37 49 73 100 72 ## spell 59 45 38 -31 33 48 87 72 100 var(dat$motiv) ## [1] 100 In the following, we conduct a simple linear regression. \\[sample \\ variance-covariance \\ matrix \\hat{\\sum} = \\mathbf{S} \\] m1a &lt;- lm(read ~ motiv, data=dat) (fit1a &lt;-summary(m1a)) ## ## Call: ## lm(formula = read ~ motiv, data = dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -26.0995 -6.1109 0.2342 5.2237 24.0183 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.232e-07 3.796e-01 0.00 1 ## motiv 5.300e-01 3.800e-02 13.95 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 8.488 on 498 degrees of freedom ## Multiple R-squared: 0.2809, Adjusted R-squared: 0.2795 ## F-statistic: 194.5 on 1 and 498 DF, p-value: &lt; 2.2e-16 library(lavaan) ## Warning: package &#39;lavaan&#39; was built under R version 3.6.3 ## This is lavaan 0.6-8 ## lavaan is FREE software! Please report any bugs. #simple regression using lavaan m1b &lt;- &#39; # regressions read ~ 1+ motiv # variance (optional) motiv ~~ motiv &#39; fit1b &lt;- sem(m1b, data=dat) summary(fit1b) ## lavaan 0.6-8 ended normally after 14 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 5 ## ## Number of observations 500 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## read ~ ## motiv 0.530 0.038 13.975 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .read -0.000 0.379 -0.000 1.000 ## motiv 0.000 0.447 0.000 1.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## motiv 99.800 6.312 15.811 0.000 ## .read 71.766 4.539 15.811 0.000 "],
["real-data-example-multiple-linear-regression.html", "Chapter 4 Real data example (Multiple linear regression)", " Chapter 4 Real data example (Multiple linear regression) m2 &lt;- &#39; # regressions read ~ 1 + ppsych + motiv # covariance ppsych ~~ motiv &#39; fit2 &lt;- sem(m2, data=dat) summary(fit2) ## lavaan 0.6-8 ended normally after 34 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 500 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## read ~ ## ppsych -0.275 0.037 -7.385 0.000 ## motiv 0.461 0.037 12.404 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## ppsych ~~ ## motiv -24.950 4.601 -5.423 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .read 0.000 0.360 0.000 1.000 ## ppsych -0.000 0.447 -0.000 1.000 ## motiv 0.000 0.447 0.000 1.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .read 64.708 4.092 15.811 0.000 ## ppsych 99.800 6.312 15.811 0.000 ## motiv 99.800 6.312 15.811 0.000 "],
["bootstrapping.html", "Chapter 5 Bootstrapping 5.1 Warning 5.2 Introduction 5.3 Normal distribution, SD, SE 5.4 Sample function 5.5 Proportion 5.6 boot package 5.7 Concept of Percentile 5.8 Use Boot for correlation 5.9 Use R for mediation", " Chapter 5 Bootstrapping 5.1 Warning Warning: This page is for my own personal study purpose. Distribution is prohibited. 5.2 Introduction The following note is made when I was studying Bret Larget’s note posted online. http://pages.stat.wisc.edu/~larget/stat302/chap3.pdf He used the data from LOck5data as an example. library(Lock5Data) data(CommuteAtlanta) str(CommuteAtlanta) ## &#39;data.frame&#39;: 500 obs. of 5 variables: ## $ City : Factor w/ 1 level &quot;Atlanta&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ Age : int 19 55 48 45 48 43 48 41 47 39 ... ## $ Distance: int 10 45 12 4 15 33 15 4 25 1 ... ## $ Time : int 15 60 45 10 30 60 45 10 25 15 ... ## $ Sex : Factor w/ 2 levels &quot;F&quot;,&quot;M&quot;: 2 2 2 1 1 2 2 1 2 1 ... time.mean = with(CommuteAtlanta, mean(Time)) time.mean ## [1] 29.11 Now, he sampled a (b X n) table. Note that, the Atlanta data has 500 row, as it has 500 observations (or, people). But, in the following new matrix, it is a (1000 times 500) table. Also, it should be noted that the logic of sample function in R. This webpage provides some insight into this function. Basically, the following R code randomly sample a bigger sample of (1000 times 500) from those 500 data points. After that, the matrix function put such (1000 times 500) data points into a matrix of (1000 times 500). B = 1000 n = nrow(CommuteAtlanta) boot.samples = matrix(sample(CommuteAtlanta$Time, size = B * n, replace = TRUE), B, n) Next, we need to calculate the mean for each row. Remember, we have 1000 rows. Note that, 1 in the apply function indicates that we calculate means on each row, whereas 2 indicates to each column. boot.statistics = apply(boot.samples, 1, mean) We can then plot all the means. require(ggplot2) ## Loading required package: ggplot2 ## Warning: package &#39;ggplot2&#39; was built under R version 3.6.3 ggplot(data.frame(meanTime = boot.statistics),aes(x=meanTime)) + geom_histogram(binwidth=0.25,aes(y=..density..)) + geom_density(color=&quot;red&quot;) time.se = sd(boot.statistics) time.se ## [1] 0.8924831 me = ceiling(10 * 2 * time.se)/10 me ## [1] 1.8 round(time.mean, 1) + c(-1, 1) * me ## [1] 27.3 30.9 5.3 Normal distribution, SD, SE Note, if we do not use bootstraping, we can use the standard CI formula (https://www.mathsisfun.com/data/confidence-interval.html). This formula assumes normal distribution. As we can see, this is close to the result based on the bootstrapping method. \\[\\overline{X} \\pm Z \\frac{S}{\\sqrt{n}}=29.11 \\pm 1.96 \\frac{20.72}{\\sqrt{500}}=27.29, 30.93\\] Note that, in the following, the author used 2 times SE to calculate the CI. The relationship between SD and SE: “Now the sample mean will vary from sample to sample; the way this variation occurs is described by the “sampling distribution” of the mean. We can estimate how much sample means will vary from the standard deviation of this sampling distribution, which we call the standard error (SE) of the estimate of the mean. As the standard error is a type of standard deviation, confusion is understandable. Another way of considering the standard error is as a measure of the precision of the sample mean.\" (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1255808/) boot.mean = function(x,B,binwidth=NULL) { n = length(x) boot.samples = matrix( sample(x,size=n*B,replace=TRUE), B, n) boot.statistics = apply(boot.samples,1,mean) se = sd(boot.statistics) require(ggplot2) if ( is.null(binwidth) ) binwidth = diff(range(boot.statistics))/30 p = ggplot(data.frame(x=boot.statistics),aes(x=x)) + geom_histogram(aes(y=..density..),binwidth=binwidth) + geom_density(color=&quot;red&quot;) plot(p) interval = mean(x) + c(-1,1)*2*se print( interval ) return( list(boot.statistics = boot.statistics, interval=interval, se=se, plot=p) ) } out = with(CommuteAtlanta, boot.mean(Distance, B = 1000)) ## [1] 16.88967 19.42233 5.4 Sample function To understand the function of sample in R. sample(20,replace = TRUE) ## [1] 10 10 7 9 18 10 11 9 9 7 10 10 18 14 6 5 9 17 1 14 The following uses loop to do the resampling. It uses sample function to index the numbers that they want to sample from the original sample. That is, [] suggests the indexing. n = length(CommuteAtlanta$Distance) B = 1000 result = rep(NA, B) for (i in 1:B) { boot.sample = sample(n, replace = TRUE) result[i] = mean(CommuteAtlanta$Distance[boot.sample]) } with(CommuteAtlanta, mean(Distance) + c(-1, 1) * 2 * sd(result)) ## [1] 16.92086 19.39114 5.5 Proportion So far, we have dealed with means. How about porpotions?Remember that, when calculating means, it starts with a single column of data to calculate the mean. Similarly, when calculating porpotions, you can just use a single column of data. reeses = c(rep(1, 11), rep(0, 19)) reeses.boot = boot.mean(reeses, 1000, binwidth = 1/30) ## [1] 0.1972970 0.5360364 However, if we have 48 students (i.e., 48 observations) and thus we have a bigger sample. However, how can we do re-sampling? Based on the note, it is kind of simple. They group them together and then resample from it. Note that, when they re-sampling, the programming do not distinguish the difference between 48 observations. But just combined them as a single column (741+699=1440), and then generate a very long column (1440 times 1000) and then reshape it into a matrix (1440 time 1000). This is the basic logic of the boot.mean function. reeses = c(rep(1, 741), rep(0, 699)) reeses.boot = boot.mean(reeses, 1000, binwidth = 0.005) ## [1] 0.4888569 0.5403097 5.6 boot package After having a basic idea of boostrapping, we can then use the package of boot. library(boot) ## Warning: package &#39;boot&#39; was built under R version 3.6.3 data(CommuteAtlanta) my.mean = function(x, indices) { return( mean( x[indices] ) ) } time.boot = boot(CommuteAtlanta$Time, my.mean, 10000) boot.ci(time.boot) ## Warning in boot.ci(time.boot): bootstrap variances needed for studentized ## intervals ## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS ## Based on 10000 bootstrap replicates ## ## CALL : ## boot.ci(boot.out = time.boot) ## ## Intervals : ## Level Normal Basic ## 95% (27.33, 30.90 ) (27.27, 30.83 ) ## ## Level Percentile BCa ## 95% (27.39, 30.95 ) (27.46, 31.06 ) ## Calculations and Intervals on Original Scale 5.7 Concept of Percentile require(Lock5Data) data(ImmuneTea) tea = with(ImmuneTea, InterferonGamma[Drink==&quot;Tea&quot;]) coffee = with(ImmuneTea, InterferonGamma[Drink==&quot;Coffee&quot;]) tea.mean = mean(tea) coffee.mean = mean(coffee) tea.n = length(tea) coffee.n = length(coffee) B = 500 # create empty arrays for the means of each sample tea.boot = numeric(B) coffee.boot = numeric(B) # Use a for loop to take the samples for ( i in 1:B ) { tea.boot[i] = mean(sample(tea,size=tea.n,replace=TRUE)) coffee.boot[i] = mean(sample(coffee,size=coffee.n,replace=TRUE)) } boot.stat = tea.boot - coffee.boot boot.stat ## [1] 28.345454545 21.000000000 16.254545455 30.690909091 19.518181818 ## [6] 7.845454545 27.309090909 17.436363636 21.690909091 9.918181818 ## [11] 19.200000000 10.563636364 16.463636364 17.218181818 14.527272727 ## [16] 38.618181818 9.172727273 26.563636364 21.809090909 2.790909091 ## [21] 14.436363636 28.927272727 17.918181818 14.663636364 37.163636364 ## [26] 21.054545455 24.345454545 11.890909091 17.618181818 13.063636364 ## [31] 26.990909091 8.200000000 24.663636364 0.590909091 13.645454545 ## [36] 21.490909091 21.900000000 29.445454545 17.472727273 9.790909091 ## [41] 20.945454545 8.590909091 5.872727273 22.472727273 18.981818182 ## [46] 11.563636364 11.972727273 25.490909091 25.927272727 34.872727273 ## [51] 9.490909091 9.627272727 11.218181818 24.872727273 36.163636364 ## [56] 14.800000000 22.254545455 11.663636364 22.336363636 17.300000000 ## [61] 21.254545455 9.272727273 21.418181818 25.700000000 15.736363636 ## [66] 13.563636364 20.354545455 5.181818182 6.209090909 11.672727273 ## [71] 8.763636364 27.527272727 20.272727273 16.054545455 18.209090909 ## [76] 7.800000000 26.754545455 28.572727273 34.036363636 14.345454545 ## [81] 22.490909091 22.390909091 30.390909091 21.790909091 2.854545455 ## [86] 19.000000000 29.172727273 26.027272727 19.736363636 18.327272727 ## [91] 16.281818182 23.445454545 18.200000000 8.509090909 12.990909091 ## [96] 21.872727273 19.945454545 28.127272727 15.245454545 24.318181818 ## [101] 39.481818182 21.718181818 -1.454545455 16.872727273 15.172727273 ## [106] 20.854545455 30.836363636 18.609090909 4.500000000 15.481818182 ## [111] 13.845454545 13.945454545 18.136363636 17.709090909 16.563636364 ## [116] 18.654545455 19.454545455 20.200000000 9.854545455 19.154545455 ## [121] 22.127272727 16.100000000 24.527272727 4.281818182 19.281818182 ## [126] 17.790909091 9.318181818 27.181818182 12.372727273 15.718181818 ## [131] 19.500000000 23.918181818 15.672727273 12.427272727 23.954545455 ## [136] 15.009090909 9.090909091 24.236363636 14.936363636 27.136363636 ## [141] 12.854545455 8.981818182 34.100000000 9.727272727 20.809090909 ## [146] 17.900000000 28.509090909 17.327272727 26.209090909 21.127272727 ## [151] 21.027272727 13.909090909 32.845454545 2.854545455 32.845454545 ## [156] 28.045454545 23.954545455 6.418181818 8.800000000 7.727272727 ## [161] 15.518181818 6.336363636 17.227272727 26.636363636 18.754545455 ## [166] 19.136363636 13.500000000 6.700000000 11.681818182 23.390909091 ## [171] 17.345454545 29.872727273 9.136363636 25.163636364 22.890909091 ## [176] 10.518181818 22.345454545 22.390909091 14.654545455 20.318181818 ## [181] 30.218181818 24.100000000 20.581818182 24.000000000 23.536363636 ## [186] 28.709090909 11.590909091 7.218181818 25.490909091 27.109090909 ## [191] 21.145454545 15.900000000 15.281818182 14.254545455 25.436363636 ## [196] 18.245454545 17.045454545 22.854545455 8.290909091 0.609090909 ## [201] 30.081818182 18.009090909 3.636363636 18.200000000 17.036363636 ## [206] 15.063636364 22.036363636 29.263636364 10.927272727 28.600000000 ## [211] 23.781818182 17.045454545 25.472727273 15.200000000 14.000000000 ## [216] 17.454545455 17.827272727 18.300000000 20.018181818 14.718181818 ## [221] 13.627272727 19.927272727 15.781818182 19.054545455 31.190909091 ## [226] 17.936363636 21.381818182 13.827272727 3.309090909 7.118181818 ## [231] 18.454545455 13.172727273 15.381818182 -0.600000000 23.181818182 ## [236] 5.545454545 9.336363636 15.890909091 22.209090909 28.918181818 ## [241] 19.481818182 15.172727273 35.836363636 35.500000000 14.563636364 ## [246] 18.245454545 24.545454545 14.118181818 13.909090909 13.645454545 ## [251] 22.709090909 18.727272727 6.736363636 27.572727273 22.018181818 ## [256] 26.527272727 21.272727273 22.718181818 21.136363636 22.427272727 ## [261] 8.581818182 24.845454545 9.172727273 2.300000000 23.072727273 ## [266] 21.663636364 13.045454545 23.981818182 21.063636364 17.700000000 ## [271] 33.181818182 4.390909091 16.845454545 18.836363636 12.400000000 ## [276] 13.581818182 24.309090909 24.272727273 16.736363636 25.481818182 ## [281] 17.345454545 11.354545455 17.145454545 16.800000000 -0.890909091 ## [286] 2.018181818 8.518181818 25.972727273 15.727272727 6.163636364 ## [291] 11.845454545 15.463636364 27.836363636 15.154545455 22.700000000 ## [296] 25.154545455 11.481818182 13.681818182 14.918181818 9.654545455 ## [301] 12.254545455 18.354545455 28.772727273 12.900000000 15.645454545 ## [306] 21.363636364 21.500000000 17.890909091 8.963636364 18.045454545 ## [311] 10.427272727 11.509090909 13.809090909 -1.181818182 30.063636364 ## [316] 22.372727273 16.481818182 12.818181818 16.363636364 8.136363636 ## [321] 17.690909091 6.627272727 18.800000000 18.636363636 15.854545455 ## [326] 14.109090909 11.218181818 17.518181818 21.081818182 11.809090909 ## [331] 33.090909091 11.081818182 14.709090909 18.918181818 0.345454545 ## [336] 11.372727273 13.454545455 21.018181818 17.409090909 27.436363636 ## [341] 19.009090909 18.863636364 15.881818182 31.427272727 14.736363636 ## [346] 18.118181818 28.345454545 20.654545455 19.609090909 23.854545455 ## [351] 15.972727273 20.627272727 22.963636364 23.400000000 20.036363636 ## [356] 32.363636364 28.272727273 17.218181818 12.963636364 10.445454545 ## [361] 4.900000000 21.472727273 25.290909091 23.981818182 24.145454545 ## [366] 25.100000000 12.818181818 24.963636364 3.900000000 1.336363636 ## [371] 11.618181818 20.881818182 28.709090909 10.981818182 8.436363636 ## [376] 17.236363636 23.263636364 29.445454545 23.727272727 16.700000000 ## [381] 31.890909091 11.845454545 5.209090909 22.309090909 20.736363636 ## [386] 0.009090909 14.654545455 15.209090909 15.045454545 14.163636364 ## [391] 11.645454545 31.390909091 8.345454545 13.445454545 23.663636364 ## [396] 28.209090909 19.036363636 13.600000000 23.572727273 7.936363636 ## [401] 6.245454545 22.081818182 30.618181818 20.700000000 25.654545455 ## [406] 31.600000000 -3.154545455 16.681818182 9.227272727 26.190909091 ## [411] 23.827272727 9.381818182 24.181818182 29.445454545 11.945454545 ## [416] 31.236363636 13.936363636 18.336363636 11.663636364 19.372727273 ## [421] 8.009090909 19.636363636 11.118181818 37.354545455 17.081818182 ## [426] 21.872727273 10.745454545 29.209090909 29.100000000 16.654545455 ## [431] 24.445454545 18.536363636 16.100000000 19.672727273 18.754545455 ## [436] 4.572727273 8.100000000 20.227272727 5.909090909 4.800000000 ## [441] 11.909090909 21.372727273 20.554545455 17.881818182 23.309090909 ## [446] 18.036363636 11.636363636 14.309090909 14.454545455 15.163636364 ## [451] 22.100000000 23.227272727 25.727272727 10.036363636 23.390909091 ## [456] 17.545454545 25.600000000 21.309090909 3.845454545 -1.590909091 ## [461] 24.090909091 18.472727273 22.645454545 6.154545455 10.118181818 ## [466] 2.709090909 16.972727273 12.954545455 9.945454545 14.000000000 ## [471] 25.372727273 15.245454545 22.954545455 17.218181818 13.072727273 ## [476] 6.354545455 23.636363636 14.172727273 19.836363636 38.218181818 ## [481] 16.627272727 24.190909091 31.381818182 19.981818182 8.463636364 ## [486] 15.618181818 22.954545455 13.000000000 31.981818182 18.363636364 ## [491] 13.590909091 19.236363636 21.590909091 14.245454545 16.909090909 ## [496] 7.590909091 16.463636364 19.309090909 17.563636364 16.818181818 # Find endpoints for 90%, 95%, and 99% bootstrap confidence intervals using percentiles. # 90%: 5% 95% quantile(boot.stat,c(0.05,0.95)) ## 5% 95% ## 4.788636 30.698182 # 95%: 2.5% 97.5% quantile(boot.stat,c(0.025,0.975)) ## 2.5% 97.5% ## 2.494318 32.974318 # 99%: 0.5% 99.5% quantile(boot.stat,c(0.005,0.995)) ## 0.5% 99.5% ## -1.319545 37.790682 5.8 Use Boot for correlation The following code is from: https://blog.methodsconsultants.com/posts/understanding-bootstrap-confidence-interval-output-from-the-r-boot-package/ This page is for my own personal study purpose. Distribution is prohibited. data_correlation&lt;-read.csv(&quot;data_correlation.csv&quot;,fileEncoding=&quot;UTF-8-BOM&quot;) data_correlation ## Student LSAT GPA ## 1 1 576 3.39 ## 2 2 635 3.30 ## 3 3 558 2.81 ## 4 4 578 3.03 ## 5 5 666 3.44 ## 6 6 580 3.07 ## 7 7 555 3.00 ## 8 8 661 3.43 ## 9 9 651 3.36 ## 10 10 605 3.13 ## 11 11 653 3.12 ## 12 12 575 2.74 ## 13 13 545 2.76 ## 14 14 572 2.88 ## 15 15 594 2.96 cor.test(data_correlation$LSAT,data_correlation$GPA) ## ## Pearson&#39;s product-moment correlation ## ## data: data_correlation$LSAT and data_correlation$GPA ## t = 4.4413, df = 13, p-value = 0.0006651 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.4385108 0.9219648 ## sample estimates: ## cor ## 0.7763745 5.9 Use R for mediation https://advstats.psychstat.org/book/mediation/index.php "]
]
