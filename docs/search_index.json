[
["index.html", "SEM and R Chapter 1 SEM and R", " SEM and R Bill 2021-04-22 Chapter 1 SEM and R This is the starting point. "],
["intro.html", "Chapter 2 Introduction 2.1 Definitions (Basic Concepts) 2.2 The path diagram 2.3 Lavaan syntax 2.4 Regression and path analysis", " Chapter 2 Introduction The following R codes and texts are from UCLA website “https://stats.idre.ucla.edu/r/seminars/rsem/” and I do not own the copyright of the R codes or texts. I wrote this R Markdown file for my own study purpose. Given this consideration, please do NOT distribute this page in any way. 2.1 Definitions (Basic Concepts) 2.1.1 Observed variable Observed variable: A variable that exists in the data (a.k.a item or manifest variable) 2.1.2 Latent variable Latent variable: A variable that is constructed and does not exist in the data. 2.1.3 Exogenous variable Exogenous variable: An independent variable either observed (X) or latent (\\(\\xi\\)) that explains an engogenous variable. 2.1.4 Endogenous variable Endogenous variable: A dependent variable, either observed (Y) or latent (\\(\\eta\\)) that has a causal path leading to it. 2.1.5 Measurement model Measurement model: A model that links obseved variables with latent variables. 2.1.6 Indicator (in a measurement model) Indicator: An observed variable in a measurement model (can be exogenous or endogenous). 2.1.7 Factor Factor: A latent variable defined by its indicators (can be exogenous or endogeous). 2.1.8 Loading Loading: A path between an indicator and a factor. 2.1.9 Structural model Structural model: A model that specifies casual relationships among exogeous variables to endogeous variables (can be observed or latent). 2.1.10 Regerssion path Regression path: A path between exogeous and endogeous variables (can be observed or latent). 2.2 The path diagram Circles represent latent variables. Squares represent observed indicators. Triangles represent intercepts or means. One way arrows represent paths. Two-way arrows represent either variances or covariances. 2.3 Lavaan syntax \\(\\sim\\) predict: used for regression of observed outcome to observed predictors (e.g., \\(y \\sim x\\)). \\(= \\sim\\) indicator: used for latent variable to observed indicator in factor analysis measurement models (e.g., \\(f= \\sim q+r+s\\)). \\(\\sim \\sim\\) covariance: (e.g., \\(x \\sim \\sim x\\)). \\(\\sim 1\\) intercept or mean: (e.g., \\(x \\sim 1\\) estimates the mean of variable \\(x\\)). \\(1*\\) fixes parameter or loading to one: (e.g., \\(f =\\sim 1*q\\)). \\(NA *\\) free parameter or loading: used to override default marker method (e.g., \\(f=\\sim NA * q\\)). \\(a*\\) lables the parameter ‘a’: used for model constraints (e.g., \\(f=\\sim a*q\\)). 2.4 Regression and path analysis \\[y_{1}=b_{0}+b_{1}x_{1}+\\epsilon_{1}\\] \\[y_{1}=\\alpha+\\gamma_{1} x_{1}+\\zeta_{1}\\] \\(x_{1}\\) single exogenous variable \\(y_{1}\\) single endogenous variable \\(b_{0}\\), \\(\\alpha_{1}\\) intercept of \\(y_{1}\\) (alpha) \\(b_{1}\\), \\(\\gamma_{1}\\) regression coefficient (gamma) \\(\\epsilon_{1}\\), \\(\\zeta_{1}\\) residual of \\(y_{1}\\) (epsilon, zeta) \\(\\phi\\) variance or covariance of the exogenous variable (phi) \\(\\psi\\) residual variance or covariance of the endogenous variable (psi) "],
["real-data-example-simple-linear-regression.html", "Chapter 3 Real data example (Simple linear regression) 3.1 Read the data into the R Studio environment.", " Chapter 3 Real data example (Simple linear regression) 3.1 Read the data into the R Studio environment. It also calcuates the covariance matrix among all the variables in the data. dat &lt;- read.csv(&quot;https://stats.idre.ucla.edu/wp-content/uploads/2021/02/worland5.csv&quot;) cov(dat) ## motiv harm stabi ppsych ses verbal read arith spell ## motiv 100 77 59 -25 25 32 53 60 59 ## harm 77 100 58 -25 26 25 42 44 45 ## stabi 59 58 100 -16 18 27 36 38 38 ## ppsych -25 -25 -16 100 -42 -40 -39 -24 -31 ## ses 25 26 18 -42 100 40 43 37 33 ## verbal 32 25 27 -40 40 100 56 49 48 ## read 53 42 36 -39 43 56 100 73 87 ## arith 60 44 38 -24 37 49 73 100 72 ## spell 59 45 38 -31 33 48 87 72 100 var(dat$motiv) ## [1] 100 In the following, we conduct a simple linear regression. \\[sample \\ variance-covariance \\ matrix \\hat{\\sum} = \\mathbf{S} \\] m1a &lt;- lm(read ~ motiv, data=dat) (fit1a &lt;-summary(m1a)) ## ## Call: ## lm(formula = read ~ motiv, data = dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -26.0995 -6.1109 0.2342 5.2237 24.0183 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.232e-07 3.796e-01 0.00 1 ## motiv 5.300e-01 3.800e-02 13.95 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 8.488 on 498 degrees of freedom ## Multiple R-squared: 0.2809, Adjusted R-squared: 0.2795 ## F-statistic: 194.5 on 1 and 498 DF, p-value: &lt; 2.2e-16 library(lavaan) ## Warning: package &#39;lavaan&#39; was built under R version 3.6.3 ## This is lavaan 0.6-8 ## lavaan is FREE software! Please report any bugs. #simple regression using lavaan m1b &lt;- &#39; # regressions read ~ 1+ motiv # variance (optional) motiv ~~ motiv &#39; fit1b &lt;- sem(m1b, data=dat) summary(fit1b) ## lavaan 0.6-8 ended normally after 14 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 5 ## ## Number of observations 500 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## read ~ ## motiv 0.530 0.038 13.975 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .read -0.000 0.379 -0.000 1.000 ## motiv 0.000 0.447 0.000 1.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## motiv 99.800 6.312 15.811 0.000 ## .read 71.766 4.539 15.811 0.000 "],
["real-data-example-multiple-linear-regression.html", "Chapter 4 Real data example (Multiple linear regression)", " Chapter 4 Real data example (Multiple linear regression) m2 &lt;- &#39; # regressions read ~ 1 + ppsych + motiv # covariance ppsych ~~ motiv &#39; fit2 &lt;- sem(m2, data=dat) summary(fit2) ## lavaan 0.6-8 ended normally after 34 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 500 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## read ~ ## ppsych -0.275 0.037 -7.385 0.000 ## motiv 0.461 0.037 12.404 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## ppsych ~~ ## motiv -24.950 4.601 -5.423 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .read 0.000 0.360 0.000 1.000 ## ppsych -0.000 0.447 -0.000 1.000 ## motiv 0.000 0.447 0.000 1.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .read 64.708 4.092 15.811 0.000 ## ppsych 99.800 6.312 15.811 0.000 ## motiv 99.800 6.312 15.811 0.000 "],
["bootstrapping.html", "Chapter 5 Bootstrapping 5.1 Warning 5.2 Introduction 5.3 Normal distribution, SD, SE 5.4 Sample function 5.5 Proportion 5.6 boot package 5.7 Concept of Percentile 5.8 Bootstrapping for correlation interval 5.9 Use R for mediation", " Chapter 5 Bootstrapping 5.1 Warning Warning: This page is for my own personal study purpose. Distribution is prohibited. 5.2 Introduction The following note is made when I was studying Bret Larget’s note posted online. http://pages.stat.wisc.edu/~larget/stat302/chap3.pdf He used the data from LOck5data as an example. library(Lock5Data) data(CommuteAtlanta) str(CommuteAtlanta) ## &#39;data.frame&#39;: 500 obs. of 5 variables: ## $ City : Factor w/ 1 level &quot;Atlanta&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ Age : int 19 55 48 45 48 43 48 41 47 39 ... ## $ Distance: int 10 45 12 4 15 33 15 4 25 1 ... ## $ Time : int 15 60 45 10 30 60 45 10 25 15 ... ## $ Sex : Factor w/ 2 levels &quot;F&quot;,&quot;M&quot;: 2 2 2 1 1 2 2 1 2 1 ... time.mean = with(CommuteAtlanta, mean(Time)) time.mean ## [1] 29.11 Now, he sampled a (b X n) table. Note that, the Atlanta data has 500 row, as it has 500 observations (or, people). But, in the following new matrix, it is a (1000 times 500) table. Also, it should be noted that the logic of sample function in R. This webpage provides some insight into this function. Basically, the following R code randomly sample a bigger sample of (1000 times 500) from those 500 data points. After that, the matrix function put such (1000 times 500) data points into a matrix of (1000 times 500). B = 1000 n = nrow(CommuteAtlanta) boot.samples = matrix(sample(CommuteAtlanta$Time, size = B * n, replace = TRUE), B, n) Next, we need to calculate the mean for each row. Remember, we have 1000 rows. Note that, 1 in the apply function indicates that we calculate means on each row, whereas 2 indicates to each column. boot.statistics = apply(boot.samples, 1, mean) We can then plot all the means. require(ggplot2) ## Loading required package: ggplot2 ## Warning: package &#39;ggplot2&#39; was built under R version 3.6.3 ggplot(data.frame(meanTime = boot.statistics),aes(x=meanTime)) + geom_histogram(binwidth=0.25,aes(y=..density..)) + geom_density(color=&quot;red&quot;) time.se = sd(boot.statistics) time.se ## [1] 0.9809293 me = ceiling(10 * 2 * time.se)/10 me ## [1] 2 round(time.mean, 1) + c(-1, 1) * me ## [1] 27.1 31.1 5.3 Normal distribution, SD, SE Note, if we do not use bootstraping, we can use the standard CI formula (https://www.mathsisfun.com/data/confidence-interval.html). This formula assumes normal distribution. As we can see, this is close to the result based on the bootstrapping method. \\[\\overline{X} \\pm Z \\frac{S}{\\sqrt{n}}=29.11 \\pm 1.96 \\frac{20.72}{\\sqrt{500}}=27.29, 30.93\\] Note that, in the following, the author used 2 times SE to calculate the CI. The relationship between SD and SE: “Now the sample mean will vary from sample to sample; the way this variation occurs is described by the “sampling distribution” of the mean. We can estimate how much sample means will vary from the standard deviation of this sampling distribution, which we call the standard error (SE) of the estimate of the mean. As the standard error is a type of standard deviation, confusion is understandable. Another way of considering the standard error is as a measure of the precision of the sample mean.\" (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1255808/) boot.mean = function(x,B,binwidth=NULL) { n = length(x) boot.samples = matrix( sample(x,size=n*B,replace=TRUE), B, n) boot.statistics = apply(boot.samples,1,mean) se = sd(boot.statistics) require(ggplot2) if ( is.null(binwidth) ) binwidth = diff(range(boot.statistics))/30 p = ggplot(data.frame(x=boot.statistics),aes(x=x)) + geom_histogram(aes(y=..density..),binwidth=binwidth) + geom_density(color=&quot;red&quot;) plot(p) interval = mean(x) + c(-1,1)*2*se print( interval ) return( list(boot.statistics = boot.statistics, interval=interval, se=se, plot=p) ) } out = with(CommuteAtlanta, boot.mean(Distance, B = 1000)) ## [1] 16.97163 19.34037 5.4 Sample function To understand the function of sample in R. sample(20,replace = TRUE) ## [1] 9 5 6 1 13 19 13 15 13 4 6 4 9 2 2 14 17 7 13 1 The following uses loop to do the resampling. It uses sample function to index the numbers that they want to sample from the original sample. That is, [] suggests the indexing. n = length(CommuteAtlanta$Distance) B = 1000 result = rep(NA, B) for (i in 1:B) { boot.sample = sample(n, replace = TRUE) result[i] = mean(CommuteAtlanta$Distance[boot.sample]) } with(CommuteAtlanta, mean(Distance) + c(-1, 1) * 2 * sd(result)) ## [1] 16.89894 19.41306 5.5 Proportion So far, we have dealed with means. How about porpotions?Remember that, when calculating means, it starts with a single column of data to calculate the mean. Similarly, when calculating porpotions, you can just use a single column of data. reeses = c(rep(1, 11), rep(0, 19)) reeses.boot = boot.mean(reeses, 1000, binwidth = 1/30) ## [1] 0.1932690 0.5400644 However, if we have 48 students (i.e., 48 observations) and thus we have a bigger sample. However, how can we do re-sampling? Based on the note, it is kind of simple. They group them together and then resample from it. Note that, when they re-sampling, the programming do not distinguish the difference between 48 observations. But just combined them as a single column (741+699=1440), and then generate a very long column (1440 times 1000) and then reshape it into a matrix (1440 time 1000). This is the basic logic of the boot.mean function. reeses = c(rep(1, 741), rep(0, 699)) reeses.boot = boot.mean(reeses, 1000, binwidth = 0.005) ## [1] 0.4876605 0.5415062 5.6 boot package After having a basic idea of boostrapping, we can then use the package of boot. library(boot) ## Warning: package &#39;boot&#39; was built under R version 3.6.3 data(CommuteAtlanta) my.mean = function(x, indices) { return( mean( x[indices] ) ) } time.boot = boot(CommuteAtlanta$Time, my.mean, 10000) boot.ci(time.boot) ## Warning in boot.ci(time.boot): bootstrap variances needed for studentized ## intervals ## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS ## Based on 10000 bootstrap replicates ## ## CALL : ## boot.ci(boot.out = time.boot) ## ## Intervals : ## Level Normal Basic ## 95% (27.30, 30.90 ) (27.27, 30.88 ) ## ## Level Percentile BCa ## 95% (27.34, 30.95 ) (27.41, 31.02 ) ## Calculations and Intervals on Original Scale 5.7 Concept of Percentile require(Lock5Data) data(ImmuneTea) tea = with(ImmuneTea, InterferonGamma[Drink==&quot;Tea&quot;]) coffee = with(ImmuneTea, InterferonGamma[Drink==&quot;Coffee&quot;]) tea.mean = mean(tea) coffee.mean = mean(coffee) tea.n = length(tea) coffee.n = length(coffee) B = 500 # create empty arrays for the means of each sample tea.boot = numeric(B) coffee.boot = numeric(B) # Use a for loop to take the samples for ( i in 1:B ) { tea.boot[i] = mean(sample(tea,size=tea.n,replace=TRUE)) coffee.boot[i] = mean(sample(coffee,size=coffee.n,replace=TRUE)) } boot.stat = tea.boot - coffee.boot boot.stat ## [1] 17.8272727 14.6545455 24.4545455 25.0454545 10.1272727 2.6727273 ## [7] 31.8090909 27.1363636 12.1818182 20.4636364 13.1000000 18.4000000 ## [13] 18.3727273 10.9909091 14.3272727 4.7454545 11.9181818 16.8909091 ## [19] 34.7272727 20.8363636 14.6636364 13.5090909 22.2636364 19.2545455 ## [25] 22.5090909 5.7454545 9.3909091 8.0181818 22.5727273 1.0545455 ## [31] 19.7090909 25.4272727 28.5727273 17.2636364 23.0636364 29.3818182 ## [37] 2.9000000 23.9363636 25.7818182 28.2818182 23.4090909 11.6727273 ## [43] 21.4909091 14.0090909 23.7363636 17.0818182 30.4545455 20.0818182 ## [49] 21.3636364 15.3000000 16.5272727 32.3636364 26.9363636 13.9636364 ## [55] 12.7090909 18.5181818 6.0181818 8.6454545 9.0454545 10.5000000 ## [61] 32.7363636 21.4727273 25.5818182 17.9727273 -0.4090909 -1.3363636 ## [67] 4.0454545 19.3000000 26.0363636 12.2545455 19.9454545 12.6272727 ## [73] 21.0909091 -0.5272727 4.2727273 20.7727273 16.0545455 27.0454545 ## [79] 6.4363636 14.3727273 4.9000000 22.0000000 5.5909091 22.4272727 ## [85] 42.7000000 24.3090909 24.6000000 18.0727273 27.7000000 10.8545455 ## [91] 14.5818182 32.5727273 9.7909091 22.0727273 13.7181818 14.1636364 ## [97] 24.7000000 19.9363636 10.7909091 16.2818182 17.2909091 21.3727273 ## [103] 15.5545455 30.3636364 14.7454545 2.0272727 17.6818182 28.9818182 ## [109] 22.1818182 27.3727273 20.1454545 19.9000000 8.0000000 20.2909091 ## [115] 28.3636364 12.7454545 34.5090909 19.2272727 22.0090909 23.2090909 ## [121] 25.9272727 31.6090909 21.2545455 28.4272727 8.2272727 24.1636364 ## [127] 6.0272727 25.4090909 22.8545455 3.7818182 12.7545455 22.2090909 ## [133] 12.7636364 2.0181818 14.3090909 13.2454545 24.1000000 15.8636364 ## [139] 2.7454545 26.7000000 31.2545455 6.0454545 28.1272727 13.4363636 ## [145] 13.5181818 26.8818182 10.8090909 8.7454545 3.9090909 18.7727273 ## [151] -3.9727273 12.7454545 29.0181818 4.8636364 19.9454545 16.7363636 ## [157] 1.8727273 1.5181818 25.5818182 11.7000000 19.8454545 20.5090909 ## [163] 7.7181818 23.6636364 3.7181818 21.2727273 7.1636364 16.0545455 ## [169] 1.3909091 24.0363636 12.8909091 18.9181818 -1.7363636 14.4727273 ## [175] 9.9818182 18.9272727 26.2272727 11.6545455 15.5909091 17.6818182 ## [181] 18.6000000 25.8272727 22.7454545 20.9181818 28.4727273 21.3090909 ## [187] 9.1090909 22.5545455 27.4090909 -1.1454545 3.8636364 10.4727273 ## [193] 9.0090909 28.6363636 19.3363636 13.1000000 35.6000000 15.9363636 ## [199] 3.3363636 12.7454545 23.7454545 13.7272727 14.4363636 16.6363636 ## [205] 28.3454545 17.1727273 10.4181818 3.8000000 24.9363636 14.0272727 ## [211] 17.1090909 30.0181818 14.3818182 14.3909091 14.4454545 20.2818182 ## [217] 25.7545455 14.8363636 19.7181818 18.5818182 12.7818182 19.0181818 ## [223] 22.9818182 13.4363636 3.4181818 10.0727273 13.8545455 27.4272727 ## [229] 22.4727273 23.0090909 17.5181818 16.8545455 24.4454545 18.5272727 ## [235] -1.5818182 16.9000000 22.0636364 18.7181818 26.1363636 4.1727273 ## [241] 10.1545455 12.2818182 16.2636364 15.6000000 17.9363636 10.1727273 ## [247] 20.6363636 31.8363636 11.6545455 12.6363636 24.4818182 15.4454545 ## [253] 5.0181818 26.2090909 4.7181818 19.2000000 24.5818182 23.0454545 ## [259] 10.4090909 12.0636364 21.2818182 30.5272727 29.5727273 31.8090909 ## [265] 22.5181818 9.6909091 9.5090909 21.3454545 13.8909091 24.1090909 ## [271] 29.7272727 21.4636364 8.4636364 25.5636364 11.2818182 7.4181818 ## [277] 22.5636364 21.2818182 13.5181818 11.3272727 14.0636364 20.7545455 ## [283] 6.4000000 7.4272727 16.5909091 20.5000000 22.6818182 14.2000000 ## [289] 21.8636364 17.2818182 18.4909091 36.5181818 25.6454545 24.0090909 ## [295] 23.0000000 31.9909091 22.0454545 28.8727273 24.6818182 23.3727273 ## [301] 23.5545455 18.2727273 20.1272727 23.5727273 28.8454545 17.6636364 ## [307] 21.1363636 20.9272727 18.1363636 11.6272727 11.2636364 15.8727273 ## [313] 16.6818182 17.4727273 0.7818182 17.3000000 20.3545455 21.0909091 ## [319] 25.9909091 10.4272727 21.9545455 14.8545455 22.4545455 7.0545455 ## [325] 20.3363636 14.6272727 15.5727273 20.4727273 20.5363636 12.5636364 ## [331] 5.4909091 24.1363636 24.8363636 28.1545455 25.5363636 33.2727273 ## [337] 19.4363636 23.4545455 7.4909091 15.2000000 7.2272727 34.0090909 ## [343] 17.4545455 20.1909091 12.2181818 33.1272727 27.3454545 15.2363636 ## [349] 8.2272727 12.0545455 10.7000000 11.9181818 3.8000000 4.6272727 ## [355] 26.0181818 23.7545455 12.5000000 22.8181818 11.0363636 21.4727273 ## [361] 19.2909091 24.5727273 24.1000000 17.5272727 7.9090909 12.4000000 ## [367] 25.2272727 16.4727273 13.3000000 11.7545455 17.1727273 16.7090909 ## [373] 24.3363636 24.5727273 7.7090909 13.4909091 19.7363636 1.3181818 ## [379] 14.3090909 23.2000000 21.1909091 18.8000000 21.3636364 2.3909091 ## [385] 12.6090909 17.1272727 6.0636364 27.3272727 19.0000000 16.7090909 ## [391] 24.0454545 16.2090909 26.1818182 14.3000000 10.9818182 26.6545455 ## [397] 29.2818182 18.5818182 13.6818182 12.0818182 13.1545455 17.4000000 ## [403] 18.3909091 13.3545455 14.9272727 9.4545455 13.2818182 6.2545455 ## [409] 18.2545455 14.5909091 28.5181818 9.8727273 23.1727273 9.6636364 ## [415] 21.0454545 20.7454545 14.4000000 4.0181818 26.9181818 3.7454545 ## [421] 16.9545455 20.3000000 18.0090909 36.1181818 7.9090909 30.1000000 ## [427] 21.3545455 33.3090909 17.8454545 13.1181818 21.0818182 14.3363636 ## [433] 22.1000000 23.1909091 0.9000000 26.3545455 31.2454545 15.1545455 ## [439] 18.1272727 18.6363636 16.6727273 25.7272727 12.2090909 13.9181818 ## [445] 20.0545455 24.3545455 22.1363636 14.9000000 13.9000000 19.2181818 ## [451] 25.2727273 1.5545455 25.7363636 22.9181818 11.9636364 23.1090909 ## [457] 15.1636364 20.7272727 21.5727273 10.3000000 19.8000000 15.2545455 ## [463] 34.2818182 5.4181818 18.0363636 5.7909091 25.9181818 22.6000000 ## [469] 7.2636364 15.0727273 20.3545455 20.7454545 13.6363636 13.9272727 ## [475] 15.0363636 21.3272727 25.4181818 12.6909091 0.5909091 20.3818182 ## [481] 30.0818182 14.1454545 20.3727273 16.6363636 6.0727273 14.7727273 ## [487] 16.2454545 0.9272727 25.9909091 11.6454545 24.6454545 19.8363636 ## [493] 24.7636364 18.1090909 20.8909091 31.8636364 15.1181818 6.0636364 ## [499] 17.2090909 26.3545455 # Find endpoints for 90%, 95%, and 99% bootstrap confidence intervals using percentiles. # 90%: 5% 95% quantile(boot.stat,c(0.05,0.95)) ## 5% 95% ## 3.703182 30.113182 # 95%: 2.5% 97.5% quantile(boot.stat,c(0.025,0.975)) ## 2.5% 97.5% ## 1.352727 32.473409 # 99%: 0.5% 99.5% quantile(boot.stat,c(0.005,0.995)) ## 0.5% 99.5% ## -1.460318 35.861682 5.8 Bootstrapping for correlation interval Some data and code are from: https://blog.methodsconsultants.com/posts/understanding-bootstrap-confidence-interval-output-from-the-r-boot-package/ data_correlation&lt;-read.csv(&quot;data_correlation.csv&quot;,fileEncoding=&quot;UTF-8-BOM&quot;) data_correlation ## Student LSAT GPA ## 1 1 576 3.39 ## 2 2 635 3.30 ## 3 3 558 2.81 ## 4 4 578 3.03 ## 5 5 666 3.44 ## 6 6 580 3.07 ## 7 7 555 3.00 ## 8 8 661 3.43 ## 9 9 651 3.36 ## 10 10 605 3.13 ## 11 11 653 3.12 ## 12 12 575 2.74 ## 13 13 545 2.76 ## 14 14 572 2.88 ## 15 15 594 2.96 cor.test(data_correlation$LSAT,data_correlation$GPA) ## ## Pearson&#39;s product-moment correlation ## ## data: data_correlation$LSAT and data_correlation$GPA ## t = 4.4413, df = 13, p-value = 0.0006651 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.4385108 0.9219648 ## sample estimates: ## cor ## 0.7763745 In the following, I will write my own code to execute the bootstrapping. I set the bootstrapping number only 500, for illustrative purposes. As we can see, the distribution is not symmetrical. As we can see, the quantile result and c(-1, 1) X 2 are not the same, as the latter assumes symmetrical distribution. However, based on the histogram, we know it is not the case. Thus, quantile would be more appropriate. You can compare the result with that from the boot function. n_row = nrow(data_correlation) n_row ## [1] 15 set.seed(12345) B = 500 result = rep(NA, B) for (i in 1:B) { boot.sample = sample(n_row, replace = TRUE) result_temp = cor.test(data_correlation[boot.sample,]$LSAT,data_correlation[boot.sample,]$GPA) result[i]=result_temp$estimate } hist(result) # 95%: 2.5% 97.5% quantile(result,c(0.025,0.975)) ## 2.5% 97.5% ## 0.4369293 0.9556859 sd(result) ## [1] 0.1342631 mean(result) + c(-1, 1) * 1.96 * sd(result) ## [1] 0.5107704 1.0370816 cor(data_correlation$LSAT,data_correlation$GPA) ## [1] 0.7763745 cor(data_correlation$LSAT,data_correlation$GPA)+ c(-1, 1) * 1.96 * sd(result) ## [1] 0.5132189 1.0395301 # why add 0.005? Not sure. The following is from the webpage. Later note: please refer to the webpage, as it provides the logic of basic interval. 0.776+0.005+c(-1, 1) * 1.96 * 0.131 ## [1] 0.52424 1.03776 In the blog mentioned above, the author used the boot function in R. For the logic of basic interval, please refer to: https://blog.methodsconsultants.com/posts/understanding-bootstrap-confidence-interval-output-from-the-r-boot-package/ library(boot) get_r &lt;- function(data, indices, x, y) { d &lt;- data[indices, ] r &lt;- round(as.numeric(cor(d[x], d[y])), 3) r} set.seed(12345) boot_out &lt;- boot( data_correlation, x = &quot;LSAT&quot;, y = &quot;GPA&quot;, R = 500, statistic = get_r ) boot.ci(boot_out) ## Warning in boot.ci(boot_out): bootstrap variances needed for studentized ## intervals ## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS ## Based on 500 bootstrap replicates ## ## CALL : ## boot.ci(boot.out = boot_out) ## ## Intervals : ## Level Normal Basic ## 95% ( 0.5247, 1.0368 ) ( 0.5900, 1.0911 ) ## ## Level Percentile BCa ## 95% ( 0.4609, 0.9620 ) ( 0.3948, 0.9443 ) ## Calculations and Intervals on Original Scale ## Some BCa intervals may be unstable 5.9 Use R for mediation https://advstats.psychstat.org/book/mediation/index.php "]
]
