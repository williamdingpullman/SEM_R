[
["index.html", "SEM and R Chapter 1 SEM and R", " SEM and R Bill 2021-04-21 Chapter 1 SEM and R This is the starting point. "],
["intro.html", "Chapter 2 Introduction 2.1 Definitions (Basic Concepts) 2.2 The path diagram 2.3 Lavaan syntax 2.4 Regression and path analysis", " Chapter 2 Introduction The following R codes and texts are from UCLA website “https://stats.idre.ucla.edu/r/seminars/rsem/” and I do not own the copyright of the R codes or texts. I wrote this R Markdown file for my own study purpose. Given this consideration, please do NOT distribute this page in any way. 2.1 Definitions (Basic Concepts) 2.1.1 Observed variable Observed variable: A variable that exists in the data (a.k.a item or manifest variable) 2.1.2 Latent variable Latent variable: A variable that is constructed and does not exist in the data. 2.1.3 Exogenous variable Exogenous variable: An independent variable either observed (X) or latent (\\(\\xi\\)) that explains an engogenous variable. 2.1.4 Endogenous variable Endogenous variable: A dependent variable, either observed (Y) or latent (\\(\\eta\\)) that has a causal path leading to it. 2.1.5 Measurement model Measurement model: A model that links obseved variables with latent variables. 2.1.6 Indicator (in a measurement model) Indicator: An observed variable in a measurement model (can be exogenous or endogenous). 2.1.7 Factor Factor: A latent variable defined by its indicators (can be exogenous or endogeous). 2.1.8 Loading Loading: A path between an indicator and a factor. 2.1.9 Structural model Structural model: A model that specifies casual relationships among exogeous variables to endogeous variables (can be observed or latent). 2.1.10 Regerssion path Regression path: A path between exogeous and endogeous variables (can be observed or latent). 2.2 The path diagram Circles represent latent variables. Squares represent observed indicators. Triangles represent intercepts or means. One way arrows represent paths. Two-way arrows represent either variances or covariances. 2.3 Lavaan syntax \\(\\sim\\) predict: used for regression of observed outcome to observed predictors (e.g., \\(y \\sim x\\)). \\(= \\sim\\) indicator: used for latent variable to observed indicator in factor analysis measurement models (e.g., \\(f= \\sim q+r+s\\)). \\(\\sim \\sim\\) covariance: (e.g., \\(x \\sim \\sim x\\)). \\(\\sim 1\\) intercept or mean: (e.g., \\(x \\sim 1\\) estimates the mean of variable \\(x\\)). \\(1*\\) fixes parameter or loading to one: (e.g., \\(f =\\sim 1*q\\)). \\(NA *\\) free parameter or loading: used to override default marker method (e.g., \\(f=\\sim NA * q\\)). \\(a*\\) lables the parameter ‘a’: used for model constraints (e.g., \\(f=\\sim a*q\\)). 2.4 Regression and path analysis \\[y_{1}=b_{0}+b_{1}x_{1}+\\epsilon_{1}\\] \\[y_{1}=\\alpha+\\gamma_{1} x_{1}+\\zeta_{1}\\] \\(x_{1}\\) single exogenous variable \\(y_{1}\\) single endogenous variable \\(b_{0}\\), \\(\\alpha_{1}\\) intercept of \\(y_{1}\\) (alpha) \\(b_{1}\\), \\(\\gamma_{1}\\) regression coefficient (gamma) \\(\\epsilon_{1}\\), \\(\\zeta_{1}\\) residual of \\(y_{1}\\) (epsilon, zeta) \\(\\phi\\) variance or covariance of the exogenous variable (phi) \\(\\psi\\) residual variance or covariance of the endogenous variable (psi) "],
["real-data-example-simple-linear-regression.html", "Chapter 3 Real data example (Simple linear regression) 3.1 Read the data into the R Studio environment.", " Chapter 3 Real data example (Simple linear regression) 3.1 Read the data into the R Studio environment. It also calcuates the covariance matrix among all the variables in the data. dat &lt;- read.csv(&quot;https://stats.idre.ucla.edu/wp-content/uploads/2021/02/worland5.csv&quot;) cov(dat) ## motiv harm stabi ppsych ses verbal read arith spell ## motiv 100 77 59 -25 25 32 53 60 59 ## harm 77 100 58 -25 26 25 42 44 45 ## stabi 59 58 100 -16 18 27 36 38 38 ## ppsych -25 -25 -16 100 -42 -40 -39 -24 -31 ## ses 25 26 18 -42 100 40 43 37 33 ## verbal 32 25 27 -40 40 100 56 49 48 ## read 53 42 36 -39 43 56 100 73 87 ## arith 60 44 38 -24 37 49 73 100 72 ## spell 59 45 38 -31 33 48 87 72 100 var(dat$motiv) ## [1] 100 In the following, we conduct a simple linear regression. \\[sample \\ variance-covariance \\ matrix \\hat{\\sum} = \\mathbf{S} \\] m1a &lt;- lm(read ~ motiv, data=dat) (fit1a &lt;-summary(m1a)) ## ## Call: ## lm(formula = read ~ motiv, data = dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -26.0995 -6.1109 0.2342 5.2237 24.0183 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.232e-07 3.796e-01 0.00 1 ## motiv 5.300e-01 3.800e-02 13.95 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 8.488 on 498 degrees of freedom ## Multiple R-squared: 0.2809, Adjusted R-squared: 0.2795 ## F-statistic: 194.5 on 1 and 498 DF, p-value: &lt; 2.2e-16 library(lavaan) ## Warning: package &#39;lavaan&#39; was built under R version 3.6.3 ## This is lavaan 0.6-8 ## lavaan is FREE software! Please report any bugs. #simple regression using lavaan m1b &lt;- &#39; # regressions read ~ 1+ motiv # variance (optional) motiv ~~ motiv &#39; fit1b &lt;- sem(m1b, data=dat) summary(fit1b) ## lavaan 0.6-8 ended normally after 14 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 5 ## ## Number of observations 500 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## read ~ ## motiv 0.530 0.038 13.975 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .read -0.000 0.379 -0.000 1.000 ## motiv 0.000 0.447 0.000 1.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## motiv 99.800 6.312 15.811 0.000 ## .read 71.766 4.539 15.811 0.000 "],
["real-data-example-multiple-linear-regression.html", "Chapter 4 Real data example (Multiple linear regression)", " Chapter 4 Real data example (Multiple linear regression) m2 &lt;- &#39; # regressions read ~ 1 + ppsych + motiv # covariance ppsych ~~ motiv &#39; fit2 &lt;- sem(m2, data=dat) summary(fit2) ## lavaan 0.6-8 ended normally after 34 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 500 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## read ~ ## ppsych -0.275 0.037 -7.385 0.000 ## motiv 0.461 0.037 12.404 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## ppsych ~~ ## motiv -24.950 4.601 -5.423 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .read 0.000 0.360 0.000 1.000 ## ppsych -0.000 0.447 -0.000 1.000 ## motiv 0.000 0.447 0.000 1.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .read 64.708 4.092 15.811 0.000 ## ppsych 99.800 6.312 15.811 0.000 ## motiv 99.800 6.312 15.811 0.000 "],
["bootstrapping.html", "Chapter 5 Bootstrapping 5.1 Introduction 5.2 Normal distribution, SD, SE 5.3 Sample function 5.4 Proportion 5.5 boot package 5.6 Concept of Percentile", " Chapter 5 Bootstrapping 5.1 Introduction The following note is made when I was studying Bret Larget’s note posted online. http://pages.stat.wisc.edu/~larget/stat302/chap3.pdf He used the data from LOck5data as an example. library(Lock5Data) data(CommuteAtlanta) str(CommuteAtlanta) ## &#39;data.frame&#39;: 500 obs. of 5 variables: ## $ City : Factor w/ 1 level &quot;Atlanta&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ Age : int 19 55 48 45 48 43 48 41 47 39 ... ## $ Distance: int 10 45 12 4 15 33 15 4 25 1 ... ## $ Time : int 15 60 45 10 30 60 45 10 25 15 ... ## $ Sex : Factor w/ 2 levels &quot;F&quot;,&quot;M&quot;: 2 2 2 1 1 2 2 1 2 1 ... time.mean = with(CommuteAtlanta, mean(Time)) time.mean ## [1] 29.11 Now, he sampled a (b X n) table. Note that, the Atlanta data has 500 row, as it has 500 observations (or, people). But, in the following new matrix, it is a (1000 times 500) table. Also, it should be noted that the logic of sample function in R. This webpage provides some insight into this function. Basically, the following R code randomly sample a bigger sample of (1000 times 500) from those 500 data points. After that, the matrix function put such (1000 times 500) data points into a matrix of (1000 times 500). B = 1000 n = nrow(CommuteAtlanta) boot.samples = matrix(sample(CommuteAtlanta$Time, size = B * n, replace = TRUE), B, n) Next, we need to calculate the mean for each row. Remember, we have 1000 rows. Note that, 1 in the apply function indicates that we calculate means on each row, whereas 2 indicates to each column. boot.statistics = apply(boot.samples, 1, mean) We can then plot all the means. require(ggplot2) ## Loading required package: ggplot2 ## Warning: package &#39;ggplot2&#39; was built under R version 3.6.3 ggplot(data.frame(meanTime = boot.statistics),aes(x=meanTime)) + geom_histogram(binwidth=0.25,aes(y=..density..)) + geom_density(color=&quot;red&quot;) time.se = sd(boot.statistics) time.se ## [1] 0.9132396 me = ceiling(10 * 2 * time.se)/10 me ## [1] 1.9 round(time.mean, 1) + c(-1, 1) * me ## [1] 27.2 31.0 5.2 Normal distribution, SD, SE Note, if we do not use bootstraping, we can use the standard CI formula (https://www.mathsisfun.com/data/confidence-interval.html). This formula assumes normal distribution. As we can see, this is close to the result based on the bootstrapping method. \\[\\overline{X} \\pm Z \\frac{S}{\\sqrt{n}}=29.11 \\pm 1.96 \\frac{20.72}{\\sqrt{500}}=27.29, 30.93\\] Note that, in the following, the author used 2 times SE to calculate the CI. The relationship between SD and SE: “Now the sample mean will vary from sample to sample; the way this variation occurs is described by the “sampling distribution” of the mean. We can estimate how much sample means will vary from the standard deviation of this sampling distribution, which we call the standard error (SE) of the estimate of the mean. As the standard error is a type of standard deviation, confusion is understandable. Another way of considering the standard error is as a measure of the precision of the sample mean.\" (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1255808/) boot.mean = function(x,B,binwidth=NULL) { n = length(x) boot.samples = matrix( sample(x,size=n*B,replace=TRUE), B, n) boot.statistics = apply(boot.samples,1,mean) se = sd(boot.statistics) require(ggplot2) if ( is.null(binwidth) ) binwidth = diff(range(boot.statistics))/30 p = ggplot(data.frame(x=boot.statistics),aes(x=x)) + geom_histogram(aes(y=..density..),binwidth=binwidth) + geom_density(color=&quot;red&quot;) plot(p) interval = mean(x) + c(-1,1)*2*se print( interval ) return( list(boot.statistics = boot.statistics, interval=interval, se=se, plot=p) ) } out = with(CommuteAtlanta, boot.mean(Distance, B = 1000)) ## [1] 16.94338 19.36862 5.3 Sample function To understand the function of sample in R. sample(20,replace = TRUE) ## [1] 1 3 11 6 10 16 14 6 14 6 12 16 5 11 16 20 16 11 4 3 The following uses loop to do the resampling. It uses sample function to index the numbers that they want to sample from the original sample. That is, [] suggests the indexing. n = length(CommuteAtlanta$Distance) B = 1000 result = rep(NA, B) for (i in 1:B) { boot.sample = sample(n, replace = TRUE) result[i] = mean(CommuteAtlanta$Distance[boot.sample]) } with(CommuteAtlanta, mean(Distance) + c(-1, 1) * 2 * sd(result)) ## [1] 16.93274 19.37926 5.4 Proportion So far, we have dealed with means. How about porpotions?Remember that, when calculating means, it starts with a single column of data to calculate the mean. Similarly, when calculating porpotions, you can just use a single column of data. reeses = c(rep(1, 11), rep(0, 19)) reeses.boot = boot.mean(reeses, 1000, binwidth = 1/30) ## [1] 0.1887391 0.5445942 However, if we have 48 students (i.e., 48 observations) and thus we have a bigger sample. However, how can we do re-sampling? Based on the note, it is kind of simple. They group them together and then resample from it. Note that, when they re-sampling, the programming do not distinguish the difference between 48 observations. But just combined them as a single column (741+699=1440), and then generate a very long column (1440 times 1000) and then reshape it into a matrix (1440 time 1000). This is the basic logic of the boot.mean function. reeses = c(rep(1, 741), rep(0, 699)) reeses.boot = boot.mean(reeses, 1000, binwidth = 0.005) ## [1] 0.4884999 0.5406668 5.5 boot package After having a basic idea of boostrapping, we can then use the package of boot. library(boot) ## Warning: package &#39;boot&#39; was built under R version 3.6.3 data(CommuteAtlanta) my.mean = function(x, indices) { return( mean( x[indices] ) ) } time.boot = boot(CommuteAtlanta$Time, my.mean, 10000) boot.ci(time.boot) ## Warning in boot.ci(time.boot): bootstrap variances needed for studentized ## intervals ## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS ## Based on 10000 bootstrap replicates ## ## CALL : ## boot.ci(boot.out = time.boot) ## ## Intervals : ## Level Normal Basic ## 95% (27.29, 30.92 ) (27.22, 30.87 ) ## ## Level Percentile BCa ## 95% (27.35, 31.00 ) (27.42, 31.10 ) ## Calculations and Intervals on Original Scale 5.6 Concept of Percentile require(Lock5Data) data(ImmuneTea) tea = with(ImmuneTea, InterferonGamma[Drink==&quot;Tea&quot;]) coffee = with(ImmuneTea, InterferonGamma[Drink==&quot;Coffee&quot;]) tea.mean = mean(tea) coffee.mean = mean(coffee) tea.n = length(tea) coffee.n = length(coffee) B = 500 # create empty arrays for the means of each sample tea.boot = numeric(B) coffee.boot = numeric(B) # Use a for loop to take the samples for ( i in 1:B ) { tea.boot[i] = mean(sample(tea,size=tea.n,replace=TRUE)) coffee.boot[i] = mean(sample(coffee,size=coffee.n,replace=TRUE)) } boot.stat = tea.boot - coffee.boot boot.stat ## [1] 28.154545455 21.636363636 17.518181818 8.990909091 27.409090909 ## [6] 14.045454545 15.209090909 19.927272727 26.509090909 23.090909091 ## [11] 21.563636364 17.063636364 22.872727273 10.318181818 24.909090909 ## [16] 20.145454545 14.336363636 17.590909091 4.781818182 24.036363636 ## [21] 15.172727273 0.390909091 14.772727273 29.454545455 -1.472727273 ## [26] 16.490909091 17.390909091 21.063636364 12.481818182 17.636363636 ## [31] 13.454545455 19.600000000 14.727272727 17.981818182 17.745454545 ## [36] 26.800000000 34.854545455 12.027272727 15.490909091 22.672727273 ## [41] 17.345454545 17.790909091 11.436363636 22.909090909 17.236363636 ## [46] 6.272727273 11.627272727 18.009090909 11.545454545 16.045454545 ## [51] 18.000000000 6.981818182 8.390909091 6.518181818 17.945454545 ## [56] 10.663636364 10.727272727 21.336363636 11.572727273 22.854545455 ## [61] 12.281818182 8.618181818 17.654545455 26.236363636 11.981818182 ## [66] 21.900000000 26.627272727 8.990909091 12.663636364 21.700000000 ## [71] 23.727272727 15.336363636 19.945454545 27.400000000 24.218181818 ## [76] 14.345454545 11.690909091 30.681818182 23.681818182 11.954545455 ## [81] 27.272727273 19.672727273 26.700000000 10.727272727 24.336363636 ## [86] 22.581818182 24.872727273 5.454545455 9.118181818 20.000000000 ## [91] 19.172727273 9.645454545 26.163636364 10.900000000 11.409090909 ## [96] 19.490909091 21.172727273 16.136363636 18.100000000 19.781818182 ## [101] 11.118181818 30.027272727 25.536363636 22.136363636 3.418181818 ## [106] 25.145454545 30.954545455 5.100000000 17.336363636 13.636363636 ## [111] 17.190909091 6.345454545 25.381818182 20.409090909 14.909090909 ## [116] 23.563636364 19.318181818 23.909090909 4.090909091 18.763636364 ## [121] 0.427272727 29.700000000 22.627272727 20.672727273 19.081818182 ## [126] 9.854545455 12.545454545 12.418181818 11.754545455 25.172727273 ## [131] -5.763636364 33.290909091 21.890909091 23.681818182 0.781818182 ## [136] 7.572727273 4.927272727 19.909090909 15.736363636 19.972727273 ## [141] 11.745454545 5.881818182 20.609090909 18.590909091 13.972727273 ## [146] 34.927272727 26.300000000 4.745454545 21.227272727 11.145454545 ## [151] 16.300000000 19.736363636 17.890909091 17.827272727 23.354545455 ## [156] 8.927272727 24.481818182 10.036363636 22.972727273 19.336363636 ## [161] 25.654545455 19.527272727 19.100000000 18.800000000 10.763636364 ## [166] 13.500000000 18.018181818 12.845454545 18.936363636 25.609090909 ## [171] 12.463636364 9.054545455 10.727272727 0.009090909 22.590909091 ## [176] 12.490909091 6.881818182 23.436363636 17.881818182 3.554545455 ## [181] 14.127272727 7.645454545 2.400000000 26.418181818 36.109090909 ## [186] -1.963636364 11.654545455 26.636363636 6.354545455 24.754545455 ## [191] 22.627272727 13.818181818 23.536363636 21.090909091 18.418181818 ## [196] 17.436363636 22.072727273 23.900000000 25.790909091 3.572727273 ## [201] 25.381818182 17.600000000 14.900000000 19.709090909 0.818181818 ## [206] 13.909090909 28.936363636 25.190909091 22.663636364 21.118181818 ## [211] 20.809090909 8.790909091 16.445454545 19.745454545 10.145454545 ## [216] 19.600000000 -0.163636364 -8.281818182 16.318181818 21.527272727 ## [221] 17.900000000 12.063636364 15.181818182 31.027272727 21.690909091 ## [226] 30.681818182 19.636363636 31.354545455 7.118181818 25.027272727 ## [231] 5.827272727 11.345454545 29.145454545 30.700000000 3.409090909 ## [236] 15.181818182 33.209090909 12.790909091 5.990909091 11.218181818 ## [241] 21.218181818 21.609090909 14.154545455 13.345454545 18.254545455 ## [246] 17.372727273 14.627272727 27.836363636 12.609090909 15.481818182 ## [251] 29.918181818 20.436363636 10.836363636 38.354545455 20.072727273 ## [256] 9.263636364 9.345454545 23.009090909 16.490909091 23.327272727 ## [261] 20.027272727 13.227272727 11.827272727 6.927272727 17.154545455 ## [266] 20.554545455 34.481818182 27.418181818 18.663636364 23.545454545 ## [271] 27.863636364 15.754545455 28.036363636 6.327272727 9.018181818 ## [276] 25.336363636 20.118181818 17.045454545 15.400000000 13.927272727 ## [281] 13.318181818 27.500000000 10.754545455 17.981818182 23.163636364 ## [286] 21.354545455 23.445454545 20.663636364 11.363636364 4.763636364 ## [291] 12.145454545 19.709090909 17.136363636 26.127272727 9.100000000 ## [296] 13.754545455 16.236363636 20.536363636 10.827272727 18.836363636 ## [301] 7.381818182 21.909090909 16.009090909 15.445454545 24.281818182 ## [306] 15.981818182 10.436363636 12.436363636 26.400000000 26.681818182 ## [311] 3.018181818 16.718181818 5.081818182 19.427272727 3.790909091 ## [316] 29.054545455 19.418181818 14.200000000 26.427272727 28.763636364 ## [321] 6.427272727 8.454545455 12.881818182 2.181818182 11.136363636 ## [326] 24.990909091 18.690909091 0.390909091 15.181818182 19.854545455 ## [331] 2.236363636 20.354545455 22.181818182 15.836363636 6.054545455 ## [336] 8.572727273 9.627272727 14.890909091 -2.890909091 21.400000000 ## [341] 16.200000000 25.300000000 17.990909091 18.272727273 30.845454545 ## [346] 21.072727273 21.245454545 16.590909091 12.718181818 22.309090909 ## [351] 20.800000000 15.436363636 20.490909091 16.436363636 25.063636364 ## [356] 10.109090909 26.418181818 18.554545455 23.527272727 24.418181818 ## [361] 10.536363636 26.754545455 13.390909091 7.172727273 13.172727273 ## [366] 8.190909091 10.809090909 8.363636364 0.045454545 38.981818182 ## [371] 27.000000000 29.490909091 32.036363636 29.909090909 30.781818182 ## [376] 20.463636364 4.636363636 23.636363636 21.790909091 10.227272727 ## [381] 30.781818182 7.218181818 12.418181818 32.590909091 24.027272727 ## [386] 21.600000000 26.781818182 32.136363636 16.227272727 38.918181818 ## [391] 18.663636364 8.790909091 23.981818182 14.654545455 14.054545455 ## [396] 13.400000000 13.690909091 18.481818182 22.163636364 16.036363636 ## [401] 12.127272727 31.427272727 24.454545455 27.545454545 21.081818182 ## [406] 8.681818182 16.881818182 22.636363636 10.218181818 11.336363636 ## [411] 18.136363636 12.636363636 18.309090909 31.072727273 18.509090909 ## [416] 27.936363636 10.763636364 -1.281818182 20.627272727 13.009090909 ## [421] 5.518181818 20.854545455 21.372727273 14.018181818 25.190909091 ## [426] 15.627272727 11.290909091 -9.818181818 10.990909091 17.636363636 ## [431] 0.845454545 15.763636364 26.618181818 22.454545455 25.290909091 ## [436] 19.872727273 18.736363636 26.472727273 29.863636364 12.490909091 ## [441] 12.090909091 24.863636364 29.745454545 23.818181818 22.100000000 ## [446] 22.963636364 21.427272727 37.081818182 21.463636364 29.136363636 ## [451] 4.272727273 22.618181818 21.636363636 5.127272727 20.463636364 ## [456] 21.118181818 22.418181818 22.036363636 25.681818182 34.127272727 ## [461] 17.509090909 23.645454545 22.463636364 29.300000000 14.490909091 ## [466] 24.645454545 20.872727273 23.854545455 25.390909091 36.300000000 ## [471] 25.381818182 9.363636364 22.781818182 14.754545455 6.354545455 ## [476] 12.745454545 17.927272727 17.718181818 15.927272727 12.363636364 ## [481] 13.400000000 24.654545455 20.290909091 18.054545455 12.590909091 ## [486] 21.227272727 12.618181818 7.790909091 16.136363636 2.936363636 ## [491] 37.736363636 24.772727273 21.409090909 19.336363636 22.700000000 ## [496] 9.736363636 13.500000000 22.354545455 25.800000000 15.781818182 # Find endpoints for 90%, 95%, and 99% bootstrap confidence intervals using percentiles. quantile(boot.stat,c(0.05,0.95)) ## 5% 95% ## 3.78000 30.68273 ## 5% 95% ## 4.018 29.764 quantile(boot.stat,c(0.025,0.975)) ## 2.5% 97.5% ## 0.5956818 32.9154545 ## 2.5% 97.5% ## 1.491 32.045 quantile(boot.stat,c(0.005,0.995)) ## 0.5% 99.5% ## -4.341636 38.048545 ## 0.5% 99.5% ## -3.745 36.264 "]
]
