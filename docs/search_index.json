[
["index.html", "SEM and R Chapter 1 SEM and R", " SEM and R Bill 2021-04-22 Chapter 1 SEM and R This is the starting point. "],
["intro.html", "Chapter 2 Introduction 2.1 Definitions (Basic Concepts) 2.2 The path diagram 2.3 Lavaan syntax 2.4 Regression and path analysis", " Chapter 2 Introduction The following R codes and texts are from UCLA website “https://stats.idre.ucla.edu/r/seminars/rsem/” and I do not own the copyright of the R codes or texts. I wrote this R Markdown file for my own study purpose. Given this consideration, please do NOT distribute this page in any way. 2.1 Definitions (Basic Concepts) 2.1.1 Observed variable Observed variable: A variable that exists in the data (a.k.a item or manifest variable) 2.1.2 Latent variable Latent variable: A variable that is constructed and does not exist in the data. 2.1.3 Exogenous variable Exogenous variable: An independent variable either observed (X) or latent (\\(\\xi\\)) that explains an engogenous variable. 2.1.4 Endogenous variable Endogenous variable: A dependent variable, either observed (Y) or latent (\\(\\eta\\)) that has a causal path leading to it. 2.1.5 Measurement model Measurement model: A model that links obseved variables with latent variables. 2.1.6 Indicator (in a measurement model) Indicator: An observed variable in a measurement model (can be exogenous or endogenous). 2.1.7 Factor Factor: A latent variable defined by its indicators (can be exogenous or endogeous). 2.1.8 Loading Loading: A path between an indicator and a factor. 2.1.9 Structural model Structural model: A model that specifies casual relationships among exogeous variables to endogeous variables (can be observed or latent). 2.1.10 Regerssion path Regression path: A path between exogeous and endogeous variables (can be observed or latent). 2.2 The path diagram Circles represent latent variables. Squares represent observed indicators. Triangles represent intercepts or means. One way arrows represent paths. Two-way arrows represent either variances or covariances. 2.3 Lavaan syntax \\(\\sim\\) predict: used for regression of observed outcome to observed predictors (e.g., \\(y \\sim x\\)). \\(= \\sim\\) indicator: used for latent variable to observed indicator in factor analysis measurement models (e.g., \\(f= \\sim q+r+s\\)). \\(\\sim \\sim\\) covariance: (e.g., \\(x \\sim \\sim x\\)). \\(\\sim 1\\) intercept or mean: (e.g., \\(x \\sim 1\\) estimates the mean of variable \\(x\\)). \\(1*\\) fixes parameter or loading to one: (e.g., \\(f =\\sim 1*q\\)). \\(NA *\\) free parameter or loading: used to override default marker method (e.g., \\(f=\\sim NA * q\\)). \\(a*\\) lables the parameter ‘a’: used for model constraints (e.g., \\(f=\\sim a*q\\)). 2.4 Regression and path analysis \\[y_{1}=b_{0}+b_{1}x_{1}+\\epsilon_{1}\\] \\[y_{1}=\\alpha+\\gamma_{1} x_{1}+\\zeta_{1}\\] \\(x_{1}\\) single exogenous variable \\(y_{1}\\) single endogenous variable \\(b_{0}\\), \\(\\alpha_{1}\\) intercept of \\(y_{1}\\) (alpha) \\(b_{1}\\), \\(\\gamma_{1}\\) regression coefficient (gamma) \\(\\epsilon_{1}\\), \\(\\zeta_{1}\\) residual of \\(y_{1}\\) (epsilon, zeta) \\(\\phi\\) variance or covariance of the exogenous variable (phi) \\(\\psi\\) residual variance or covariance of the endogenous variable (psi) "],
["real-data-example-simple-linear-regression.html", "Chapter 3 Real data example (Simple linear regression) 3.1 Read the data into the R Studio environment.", " Chapter 3 Real data example (Simple linear regression) 3.1 Read the data into the R Studio environment. It also calcuates the covariance matrix among all the variables in the data. dat &lt;- read.csv(&quot;https://stats.idre.ucla.edu/wp-content/uploads/2021/02/worland5.csv&quot;) cov(dat) ## motiv harm stabi ppsych ses verbal read arith spell ## motiv 100 77 59 -25 25 32 53 60 59 ## harm 77 100 58 -25 26 25 42 44 45 ## stabi 59 58 100 -16 18 27 36 38 38 ## ppsych -25 -25 -16 100 -42 -40 -39 -24 -31 ## ses 25 26 18 -42 100 40 43 37 33 ## verbal 32 25 27 -40 40 100 56 49 48 ## read 53 42 36 -39 43 56 100 73 87 ## arith 60 44 38 -24 37 49 73 100 72 ## spell 59 45 38 -31 33 48 87 72 100 var(dat$motiv) ## [1] 100 In the following, we conduct a simple linear regression. \\[sample \\ variance-covariance \\ matrix \\hat{\\sum} = \\mathbf{S} \\] m1a &lt;- lm(read ~ motiv, data=dat) (fit1a &lt;-summary(m1a)) ## ## Call: ## lm(formula = read ~ motiv, data = dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -26.0995 -6.1109 0.2342 5.2237 24.0183 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.232e-07 3.796e-01 0.00 1 ## motiv 5.300e-01 3.800e-02 13.95 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 8.488 on 498 degrees of freedom ## Multiple R-squared: 0.2809, Adjusted R-squared: 0.2795 ## F-statistic: 194.5 on 1 and 498 DF, p-value: &lt; 2.2e-16 library(lavaan) ## Warning: package &#39;lavaan&#39; was built under R version 3.6.3 ## This is lavaan 0.6-8 ## lavaan is FREE software! Please report any bugs. #simple regression using lavaan m1b &lt;- &#39; # regressions read ~ 1+ motiv # variance (optional) motiv ~~ motiv &#39; fit1b &lt;- sem(m1b, data=dat) summary(fit1b) ## lavaan 0.6-8 ended normally after 14 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 5 ## ## Number of observations 500 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## read ~ ## motiv 0.530 0.038 13.975 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .read -0.000 0.379 -0.000 1.000 ## motiv 0.000 0.447 0.000 1.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## motiv 99.800 6.312 15.811 0.000 ## .read 71.766 4.539 15.811 0.000 "],
["real-data-example-multiple-linear-regression.html", "Chapter 4 Real data example (Multiple linear regression)", " Chapter 4 Real data example (Multiple linear regression) m2 &lt;- &#39; # regressions read ~ 1 + ppsych + motiv # covariance ppsych ~~ motiv &#39; fit2 &lt;- sem(m2, data=dat) summary(fit2) ## lavaan 0.6-8 ended normally after 34 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 500 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## read ~ ## ppsych -0.275 0.037 -7.385 0.000 ## motiv 0.461 0.037 12.404 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## ppsych ~~ ## motiv -24.950 4.601 -5.423 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .read 0.000 0.360 0.000 1.000 ## ppsych -0.000 0.447 -0.000 1.000 ## motiv 0.000 0.447 0.000 1.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .read 64.708 4.092 15.811 0.000 ## ppsych 99.800 6.312 15.811 0.000 ## motiv 99.800 6.312 15.811 0.000 "],
["bootstrapping.html", "Chapter 5 Bootstrapping 5.1 Introduction 5.2 Normal distribution, SD, SE 5.3 Sample function 5.4 Proportion 5.5 boot package 5.6 Concept of Percentile 5.7 Use Boot for correlation 5.8 Use R for mediation", " Chapter 5 Bootstrapping 5.1 Introduction Warning: This page is for my own personal study purpose. Distribution is prohibited. The following note is made when I was studying Bret Larget’s note posted online. http://pages.stat.wisc.edu/~larget/stat302/chap3.pdf He used the data from LOck5data as an example. library(Lock5Data) data(CommuteAtlanta) str(CommuteAtlanta) ## &#39;data.frame&#39;: 500 obs. of 5 variables: ## $ City : Factor w/ 1 level &quot;Atlanta&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ Age : int 19 55 48 45 48 43 48 41 47 39 ... ## $ Distance: int 10 45 12 4 15 33 15 4 25 1 ... ## $ Time : int 15 60 45 10 30 60 45 10 25 15 ... ## $ Sex : Factor w/ 2 levels &quot;F&quot;,&quot;M&quot;: 2 2 2 1 1 2 2 1 2 1 ... time.mean = with(CommuteAtlanta, mean(Time)) time.mean ## [1] 29.11 Now, he sampled a (b X n) table. Note that, the Atlanta data has 500 row, as it has 500 observations (or, people). But, in the following new matrix, it is a (1000 times 500) table. Also, it should be noted that the logic of sample function in R. This webpage provides some insight into this function. Basically, the following R code randomly sample a bigger sample of (1000 times 500) from those 500 data points. After that, the matrix function put such (1000 times 500) data points into a matrix of (1000 times 500). B = 1000 n = nrow(CommuteAtlanta) boot.samples = matrix(sample(CommuteAtlanta$Time, size = B * n, replace = TRUE), B, n) Next, we need to calculate the mean for each row. Remember, we have 1000 rows. Note that, 1 in the apply function indicates that we calculate means on each row, whereas 2 indicates to each column. boot.statistics = apply(boot.samples, 1, mean) We can then plot all the means. require(ggplot2) ## Loading required package: ggplot2 ## Warning: package &#39;ggplot2&#39; was built under R version 3.6.3 ggplot(data.frame(meanTime = boot.statistics),aes(x=meanTime)) + geom_histogram(binwidth=0.25,aes(y=..density..)) + geom_density(color=&quot;red&quot;) time.se = sd(boot.statistics) time.se ## [1] 0.9340072 me = ceiling(10 * 2 * time.se)/10 me ## [1] 1.9 round(time.mean, 1) + c(-1, 1) * me ## [1] 27.2 31.0 5.2 Normal distribution, SD, SE Note, if we do not use bootstraping, we can use the standard CI formula (https://www.mathsisfun.com/data/confidence-interval.html). This formula assumes normal distribution. As we can see, this is close to the result based on the bootstrapping method. \\[\\overline{X} \\pm Z \\frac{S}{\\sqrt{n}}=29.11 \\pm 1.96 \\frac{20.72}{\\sqrt{500}}=27.29, 30.93\\] Note that, in the following, the author used 2 times SE to calculate the CI. The relationship between SD and SE: “Now the sample mean will vary from sample to sample; the way this variation occurs is described by the “sampling distribution” of the mean. We can estimate how much sample means will vary from the standard deviation of this sampling distribution, which we call the standard error (SE) of the estimate of the mean. As the standard error is a type of standard deviation, confusion is understandable. Another way of considering the standard error is as a measure of the precision of the sample mean.\" (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1255808/) boot.mean = function(x,B,binwidth=NULL) { n = length(x) boot.samples = matrix( sample(x,size=n*B,replace=TRUE), B, n) boot.statistics = apply(boot.samples,1,mean) se = sd(boot.statistics) require(ggplot2) if ( is.null(binwidth) ) binwidth = diff(range(boot.statistics))/30 p = ggplot(data.frame(x=boot.statistics),aes(x=x)) + geom_histogram(aes(y=..density..),binwidth=binwidth) + geom_density(color=&quot;red&quot;) plot(p) interval = mean(x) + c(-1,1)*2*se print( interval ) return( list(boot.statistics = boot.statistics, interval=interval, se=se, plot=p) ) } out = with(CommuteAtlanta, boot.mean(Distance, B = 1000)) ## [1] 16.93958 19.37242 5.3 Sample function To understand the function of sample in R. sample(20,replace = TRUE) ## [1] 5 11 20 20 14 15 3 10 19 13 2 2 11 8 5 8 20 16 14 10 The following uses loop to do the resampling. It uses sample function to index the numbers that they want to sample from the original sample. That is, [] suggests the indexing. n = length(CommuteAtlanta$Distance) B = 1000 result = rep(NA, B) for (i in 1:B) { boot.sample = sample(n, replace = TRUE) result[i] = mean(CommuteAtlanta$Distance[boot.sample]) } with(CommuteAtlanta, mean(Distance) + c(-1, 1) * 2 * sd(result)) ## [1] 16.94883 19.36317 5.4 Proportion So far, we have dealed with means. How about porpotions?Remember that, when calculating means, it starts with a single column of data to calculate the mean. Similarly, when calculating porpotions, you can just use a single column of data. reeses = c(rep(1, 11), rep(0, 19)) reeses.boot = boot.mean(reeses, 1000, binwidth = 1/30) ## [1] 0.1849012 0.5484321 However, if we have 48 students (i.e., 48 observations) and thus we have a bigger sample. However, how can we do re-sampling? Based on the note, it is kind of simple. They group them together and then resample from it. Note that, when they re-sampling, the programming do not distinguish the difference between 48 observations. But just combined them as a single column (741+699=1440), and then generate a very long column (1440 times 1000) and then reshape it into a matrix (1440 time 1000). This is the basic logic of the boot.mean function. reeses = c(rep(1, 741), rep(0, 699)) reeses.boot = boot.mean(reeses, 1000, binwidth = 0.005) ## [1] 0.4888704 0.5402963 5.5 boot package After having a basic idea of boostrapping, we can then use the package of boot. library(boot) ## Warning: package &#39;boot&#39; was built under R version 3.6.3 data(CommuteAtlanta) my.mean = function(x, indices) { return( mean( x[indices] ) ) } time.boot = boot(CommuteAtlanta$Time, my.mean, 10000) boot.ci(time.boot) ## Warning in boot.ci(time.boot): bootstrap variances needed for studentized ## intervals ## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS ## Based on 10000 bootstrap replicates ## ## CALL : ## boot.ci(boot.out = time.boot) ## ## Intervals : ## Level Normal Basic ## 95% (27.29, 30.94 ) (27.25, 30.91 ) ## ## Level Percentile BCa ## 95% (27.31, 30.97 ) (27.39, 31.07 ) ## Calculations and Intervals on Original Scale 5.6 Concept of Percentile require(Lock5Data) data(ImmuneTea) tea = with(ImmuneTea, InterferonGamma[Drink==&quot;Tea&quot;]) coffee = with(ImmuneTea, InterferonGamma[Drink==&quot;Coffee&quot;]) tea.mean = mean(tea) coffee.mean = mean(coffee) tea.n = length(tea) coffee.n = length(coffee) B = 500 # create empty arrays for the means of each sample tea.boot = numeric(B) coffee.boot = numeric(B) # Use a for loop to take the samples for ( i in 1:B ) { tea.boot[i] = mean(sample(tea,size=tea.n,replace=TRUE)) coffee.boot[i] = mean(sample(coffee,size=coffee.n,replace=TRUE)) } boot.stat = tea.boot - coffee.boot boot.stat ## [1] 16.7909091 18.7818182 14.2363636 14.0090909 1.4000000 16.7909091 ## [7] 16.9272727 24.8545455 21.9454545 12.3545455 23.4181818 17.4272727 ## [13] 8.8545455 20.9727273 14.3454545 17.5909091 23.5909091 8.9909091 ## [19] 6.9727273 13.1272727 8.6272727 13.7181818 3.8545455 11.9818182 ## [25] 17.3090909 30.2545455 25.0272727 20.9545455 21.9818182 19.5636364 ## [31] -0.5090909 21.8090909 29.8090909 16.1000000 8.7181818 24.4545455 ## [37] 21.5727273 27.1181818 25.0272727 20.5000000 13.4090909 27.2545455 ## [43] 14.0181818 24.7181818 27.2272727 13.1363636 24.4090909 13.9454545 ## [49] 16.3909091 22.2636364 7.5000000 31.0000000 16.2727273 1.1818182 ## [55] 23.5363636 -5.2636364 34.9090909 18.8818182 14.2000000 24.5000000 ## [61] 13.7545455 31.1000000 18.0727273 10.3636364 8.4818182 9.4818182 ## [67] 14.8818182 18.6000000 17.2090909 22.8000000 20.8636364 19.4272727 ## [73] 14.3818182 19.3909091 16.4000000 6.0181818 13.2272727 7.2454545 ## [79] 25.2454545 22.6363636 5.4636364 1.6454545 23.6090909 16.2636364 ## [85] 15.0545455 7.0636364 12.1636364 20.8454545 3.5272727 23.2090909 ## [91] 6.6909091 3.8090909 10.9181818 19.9363636 18.2727273 7.3636364 ## [97] 27.8090909 17.5181818 23.6909091 24.1454545 30.5000000 19.9727273 ## [103] 19.4090909 12.2636364 22.6181818 15.1727273 18.6636364 12.5636364 ## [109] 23.8909091 20.6181818 12.5909091 4.8818182 5.6272727 25.2909091 ## [115] 23.6272727 29.0727273 16.0636364 15.2909091 13.1363636 -0.3454545 ## [121] 4.3636364 29.6090909 3.8818182 8.8909091 17.6727273 19.0272727 ## [127] 3.9818182 16.3363636 6.8090909 22.2000000 24.4636364 23.8272727 ## [133] 19.9454545 7.0545455 29.2272727 21.7818182 19.3272727 13.3727273 ## [139] 14.4818182 18.6454545 23.4818182 20.2727273 -1.8454545 15.0818182 ## [145] 26.6727273 9.4454545 22.6272727 14.8818182 23.9363636 19.4090909 ## [151] 25.5000000 28.5000000 12.3636364 14.5545455 30.5363636 14.1000000 ## [157] 11.4636364 19.3727273 12.6272727 19.6454545 15.8818182 16.6090909 ## [163] 20.3000000 31.8727273 18.0909091 18.3636364 10.3363636 3.6363636 ## [169] 20.4727273 15.2636364 32.6000000 13.7636364 25.7727273 10.9272727 ## [175] 8.9909091 14.0181818 20.6818182 21.4818182 22.2363636 22.1272727 ## [181] 9.3727273 29.1181818 20.0818182 38.0909091 15.1272727 3.6818182 ## [187] 17.3181818 19.0090909 10.8181818 14.7909091 7.7272727 25.0909091 ## [193] 14.7272727 13.1090909 20.4454545 14.4545455 9.6363636 21.2909091 ## [199] 20.1454545 28.3363636 32.4363636 22.2545455 16.6818182 7.9090909 ## [205] 14.7818182 22.1272727 22.4363636 6.3272727 13.7818182 10.9363636 ## [211] 2.5272727 11.8363636 18.3545455 8.8727273 30.9181818 10.8727273 ## [217] 13.8545455 9.4000000 35.6818182 2.0818182 -0.3272727 9.8363636 ## [223] 18.1363636 23.1454545 26.9727273 17.6545455 12.7272727 15.6454545 ## [229] 21.4909091 20.1181818 21.1727273 16.2636364 23.8818182 6.8545455 ## [235] -2.6545455 10.8818182 21.5363636 26.3454545 25.5363636 15.9090909 ## [241] 19.1272727 12.1545455 12.6818182 11.3454545 14.2636364 15.6272727 ## [247] 14.0545455 25.2727273 12.5727273 4.0090909 14.0909091 22.1909091 ## [253] 22.7545455 25.8000000 2.4545455 15.5909091 14.9727273 11.5727273 ## [259] 23.9363636 26.0181818 17.5090909 26.7909091 26.5000000 25.1000000 ## [265] 17.2090909 24.7545455 7.4363636 3.2181818 10.7636364 23.6181818 ## [271] 17.6909091 18.7363636 24.2000000 14.4454545 20.4454545 7.8181818 ## [277] 26.1090909 18.1000000 20.8636364 7.9181818 22.1272727 23.0090909 ## [283] 18.3181818 21.6272727 29.3636364 12.4000000 8.6636364 24.3545455 ## [289] 18.5727273 15.6727273 16.2090909 12.1000000 9.0090909 20.6545455 ## [295] 21.2818182 17.4818182 8.1545455 1.5545455 9.2363636 26.8454545 ## [301] 14.5363636 6.0363636 16.0545455 10.0545455 23.2818182 27.9272727 ## [307] 11.8181818 17.1454545 16.9272727 25.4000000 26.8181818 26.3272727 ## [313] 22.0545455 15.1454545 27.6272727 17.9454545 12.3181818 5.1636364 ## [319] 23.3818182 -4.2181818 17.8000000 24.3636364 17.3454545 15.5000000 ## [325] 22.9000000 18.2000000 -2.7545455 30.8727273 13.3272727 6.9727273 ## [331] 13.2090909 9.2818182 9.0818182 12.3818182 23.8727273 6.0000000 ## [337] 7.4181818 22.1000000 20.3727273 16.6454545 7.4727273 12.5454545 ## [343] 11.9909091 13.0454545 18.5545455 30.4818182 17.8000000 12.4727273 ## [349] 13.1272727 7.4000000 20.6090909 14.5181818 19.8181818 13.2636364 ## [355] 9.7909091 14.6363636 17.2909091 22.8727273 24.6636364 6.6818182 ## [361] 24.9818182 32.3636364 20.6545455 10.8727273 11.5000000 11.1818182 ## [367] 17.3636364 23.1000000 9.4909091 10.4909091 6.9909091 3.4090909 ## [373] 27.1909091 -0.2545455 17.1818182 24.5454545 13.3454545 17.3000000 ## [379] 13.3545455 19.5909091 30.9545455 20.2000000 13.2272727 34.7090909 ## [385] 0.5727273 18.2454545 15.9909091 15.6363636 11.7181818 15.7090909 ## [391] 17.8545455 23.9727273 17.6818182 25.1090909 12.0454545 4.5818182 ## [397] 16.8727273 6.5363636 11.0181818 23.5818182 16.0090909 26.5818182 ## [403] 27.5545455 22.8000000 8.9090909 12.8909091 16.3727273 21.5000000 ## [409] 28.8818182 9.6727273 23.3272727 17.2727273 20.4818182 -0.4818182 ## [415] 10.8363636 22.3181818 12.8181818 21.7363636 16.6090909 38.0545455 ## [421] 21.6909091 7.9090909 8.3272727 12.0727273 27.0363636 19.8181818 ## [427] 21.4636364 0.3000000 0.8727273 24.8727273 1.1909091 8.2090909 ## [433] 13.3909091 5.3909091 32.1545455 22.4727273 16.1272727 32.4636364 ## [439] 22.6000000 22.4181818 11.6272727 26.4272727 10.3272727 38.7272727 ## [445] 28.9727273 21.5545455 7.8454545 20.0363636 12.7000000 21.8636364 ## [451] 3.6363636 12.6272727 10.6454545 29.7000000 3.2909091 21.8181818 ## [457] 19.6818182 9.9454545 13.3181818 19.0272727 13.2636364 20.9181818 ## [463] 19.0363636 3.6909091 6.8181818 19.0363636 4.9909091 23.7818182 ## [469] 23.1636364 16.6818182 16.5909091 13.7727273 17.8181818 13.6181818 ## [475] 10.3181818 20.5454545 2.8181818 18.0818182 11.7090909 0.3000000 ## [481] 29.3090909 22.5909091 20.3454545 19.9272727 13.5363636 13.2363636 ## [487] 24.6545455 14.7636364 3.8818182 21.2272727 19.4090909 18.0727273 ## [493] 17.9363636 28.0363636 11.2727273 20.4545455 15.4181818 19.2454545 ## [499] 13.6272727 32.1636364 # Find endpoints for 90%, 95%, and 99% bootstrap confidence intervals using percentiles. # 90%: 5% 95% quantile(boot.stat,c(0.05,0.95)) ## 5% 95% ## 3.403182 29.375909 # 95%: 2.5% 97.5% quantile(boot.stat,c(0.025,0.975)) ## 2.5% 97.5% ## 0.7152273 31.5056818 # 99%: 0.5% 99.5% quantile(boot.stat,c(0.005,0.995)) ## 0.5% 99.5% ## -2.705045 36.880045 5.7 Use Boot for correlation The following code is from: https://blog.methodsconsultants.com/posts/understanding-bootstrap-confidence-interval-output-from-the-r-boot-package/ This page is for my own personal study purpose. Distribution is prohibited. data_correlation&lt;-read.csv(&quot;data_correlation.csv&quot;,fileEncoding=&quot;UTF-8-BOM&quot;) data_correlation ## Student LSAT GPA ## 1 1 576 3.39 ## 2 2 635 3.30 ## 3 3 558 2.81 ## 4 4 578 3.03 ## 5 5 666 3.44 ## 6 6 580 3.07 ## 7 7 555 3.00 ## 8 8 661 3.43 ## 9 9 651 3.36 ## 10 10 605 3.13 ## 11 11 653 3.12 ## 12 12 575 2.74 ## 13 13 545 2.76 ## 14 14 572 2.88 ## 15 15 594 2.96 cor.test(data_correlation$LSAT,data_correlation$GPA) ## ## Pearson&#39;s product-moment correlation ## ## data: data_correlation$LSAT and data_correlation$GPA ## t = 4.4413, df = 13, p-value = 0.0006651 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.4385108 0.9219648 ## sample estimates: ## cor ## 0.7763745 5.8 Use R for mediation https://advstats.psychstat.org/book/mediation/index.php "]
]
